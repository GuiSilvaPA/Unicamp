{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copie de Aula 8 - Exercício","provenance":[{"file_id":"1rQOtuYXKh2-5fTqw9KP5nlKaeI-shK6R","timestamp":1633525995788},{"file_id":"1LpaixNlF2QrDplSrspxAWFgF6URbMz61","timestamp":1633021556046},{"file_id":"1qBaqEKlcy1Mnyhw_HKPgS-m45V8Ze2Mk","timestamp":1632932817064},{"file_id":"1iKPwoL-PtmJu0rpy1K0P4dqwZR44uDdL","timestamp":1632679088569},{"file_id":"1iCUWoyLkNU1-UmsB8YLfLvr3xwI04vIQ","timestamp":1632071575482},{"file_id":"1wpv_r96bBhIHJ3g9q3so3p8sHJ1HDk7H","timestamp":1631553851617},{"file_id":"1YW4O0K7EfSsgUe1kaZR9NswLXKVwqCb-","timestamp":1631389187602},{"file_id":"1Y3rRUiQGW5CEcPRkx_sfZGAEjNwVsw-b","timestamp":1631184728325},{"file_id":"1ONeS-lZ3vVqThueoTvQRMnZ_rJJB1yOl","timestamp":1629906878859}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"1OG5DT_dm6mk"},"source":["# Notebook de referência \n","\n","Nome: Guilherme Pereira Albino da Silva RA: 166690"]},{"cell_type":"markdown","metadata":{"id":"LZ80hHaftwUd"},"source":["## Instruções:\n","\n","Treinar e medir a acurácia de um modelo de classificação binária usando o dataset do IMDB (20k/5k amostras de treino/validação).\n","O modelo deverá ter uma camada de auto-atenção completa igual à do artigo do \"Attention is All You Need\".\n","\n","Implementar a Análise de Sentimento do IMDB, igual ao da semana passada (IMDB), mas agora usando a atenção \"completa\":\n","- Embeddings de posição\n","- Projeções lineares (WQ, WK, WV, WO)\n","- Scaled Dot-product\n","- Multi-head\n","- Layer Normalization\n","- Conexões residuais\n","- Camada de feed forward (2-layer MLP)\n","\n","Deverá ser entregue apenas a implementação matricial, ou seja, não precisa implementar a forma em laço.\n","\n","Devemos usar embeddings pretreinados do Glove como entrada para a camada de auto-atenção. Lembrar de congelá-los pois, caso contrário,  pode ocorrer overfit.\n","\n","Ao corrigir o exercicio, iremos também nos atentar na eficiencia/velocidade das implementações.\n","\n","Dicas:\n","- A dificuldade deste exercício será implementar a auto-atenção de forma matricial usando minibatches. Para lidar com exemplos de tamanho variável, deve-se truncá-los e aplicar padding.\n","\n","- Evitar usar qualquer laço na implementação matricial, pois isso a deixará muito ineficiente."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"UjzRrwafx_Pf","executionInfo":{"status":"ok","timestamp":1633526760949,"user_tz":180,"elapsed":18530,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"5784fea5-85ee-420e-f6ac-46ebde4cf420"},"source":["!pip install neptune-client"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting neptune-client\n","  Downloading neptune-client-0.12.0.tar.gz (275 kB)\n","\u001b[K     |████████████████████████████████| 275 kB 29.7 MB/s \n","\u001b[?25hCollecting bravado\n","  Downloading bravado-11.0.3-py2.py3-none-any.whl (38 kB)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (7.1.2)\n","Collecting future>=0.17.1\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 39.5 MB/s \n","\u001b[?25hRequirement already satisfied: oauthlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (3.1.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.1.5)\n","Requirement already satisfied: Pillow>=1.1.6 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (7.1.2)\n","Collecting PyJWT\n","  Downloading PyJWT-2.1.0-py3-none-any.whl (16 kB)\n","Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (2.23.0)\n","Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.3.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.15.0)\n","Collecting websocket-client!=1.0.0,>=0.35.0\n","  Downloading websocket_client-1.2.1-py2.py3-none-any.whl (52 kB)\n","\u001b[K     |████████████████████████████████| 52 kB 1.6 MB/s \n","\u001b[?25hCollecting GitPython>=2.0.8\n","  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n","\u001b[K     |████████████████████████████████| 180 kB 53.8 MB/s \n","\u001b[?25hCollecting boto3>=1.16.0\n","  Downloading boto3-1.18.55-py3-none-any.whl (131 kB)\n","\u001b[K     |████████████████████████████████| 131 kB 56.9 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from neptune-client) (21.0)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.24.3)\n","Requirement already satisfied: jsonschema<4 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (2.6.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from neptune-client) (5.4.8)\n","Collecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 8.1 MB/s \n","\u001b[?25hCollecting botocore<1.22.0,>=1.21.55\n","  Downloading botocore-1.21.55-py3-none-any.whl (8.0 MB)\n","\u001b[K     |████████████████████████████████| 8.0 MB 66.9 MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.55->boto3>=1.16.0->neptune-client) (2.8.2)\n","Collecting urllib3\n","  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 62.6 MB/s \n","\u001b[?25hCollecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=2.0.8->neptune-client) (3.7.4.3)\n","Collecting smmap<5,>=3.0.1\n","  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (2021.5.30)\n","Collecting urllib3\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 74.1 MB/s \n","\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (2.10)\n","Collecting bravado-core>=5.16.1\n","  Downloading bravado_core-5.17.0-py2.py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 6.0 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (3.13)\n","Requirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (1.0.2)\n","Collecting monotonic\n","  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n","Collecting simplejson\n","  Downloading simplejson-3.17.5-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (129 kB)\n","\u001b[K     |████████████████████████████████| 129 kB 75.3 MB/s \n","\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from bravado-core>=5.16.1->bravado->neptune-client) (2018.9)\n","Collecting swagger-spec-validator>=2.0.1\n","  Downloading swagger_spec_validator-2.7.3-py2.py3-none-any.whl (27 kB)\n","Collecting jsonref\n","  Downloading jsonref-0.2-py3-none-any.whl (9.3 kB)\n","Collecting rfc3987\n","  Downloading rfc3987-1.3.8-py2.py3-none-any.whl (13 kB)\n","Collecting strict-rfc3339\n","  Downloading strict-rfc3339-0.7.tar.gz (17 kB)\n","Collecting webcolors\n","  Downloading webcolors-1.11.1-py3-none-any.whl (9.9 kB)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->neptune-client) (2.4.7)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->neptune-client) (1.19.5)\n","Building wheels for collected packages: neptune-client, future, strict-rfc3339\n","  Building wheel for neptune-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for neptune-client: filename=neptune_client-0.12.0-py2.py3-none-any.whl size=478334 sha256=67c600c705d9c2fe8b30670c32f62e1bc6f75ff14436aad2f9774f0ee5a71390\n","  Stored in directory: /root/.cache/pip/wheels/9b/2f/0a/f16d84ff3a68368a6b7d39d199c37454d2cefaf3b99e6eb435\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=c70d18a16d29f045f7a73951f42cff122149cb91d0eadafc78eab16d654e544a\n","  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","  Building wheel for strict-rfc3339 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for strict-rfc3339: filename=strict_rfc3339-0.7-py3-none-any.whl size=18149 sha256=a106a724ea57b6d2cf751e02076f920c8c62e74a2aa8a39cbe6275f88c0201e4\n","  Stored in directory: /root/.cache/pip/wheels/f3/1d/9f/2a74caecb81b8beb9a4fbe1754203d4b7cf42ef5d39e0d2311\n","Successfully built neptune-client future strict-rfc3339\n","Installing collected packages: webcolors, urllib3, strict-rfc3339, rfc3987, jmespath, swagger-spec-validator, smmap, simplejson, jsonref, botocore, s3transfer, monotonic, gitdb, bravado-core, websocket-client, PyJWT, GitPython, future, bravado, boto3, neptune-client\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed GitPython-3.1.24 PyJWT-2.1.0 boto3-1.18.55 botocore-1.21.55 bravado-11.0.3 bravado-core-5.17.0 future-0.18.2 gitdb-4.0.7 jmespath-0.10.0 jsonref-0.2 monotonic-1.6 neptune-client-0.12.0 rfc3987-1.3.8 s3transfer-0.5.0 simplejson-3.17.5 smmap-4.0.0 strict-rfc3339-0.7 swagger-spec-validator-2.7.3 urllib3-1.25.11 webcolors-1.11.1 websocket-client-1.2.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["urllib3"]}}},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"oQkJUMueyC2Z","executionInfo":{"status":"ok","timestamp":1633526770637,"user_tz":180,"elapsed":896,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}}},"source":["import neptune.new as neptune"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ojyVOubollcH"},"source":["## Definindo os parametros"]},{"cell_type":"code","metadata":{"id":"F-YHxi_AllQZ","executionInfo":{"status":"ok","timestamp":1633526265839,"user_tz":180,"elapsed":14,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}}},"source":["params = {\n","    'vocabulary_size': 400000,\n","    'padding_idx': 400001,\n","    'max_length': 200,\n","    'dim': 300,\n","    'n_heads': 6,\n","}"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uhpAkifICdJo"},"source":["# Fixando a seed"]},{"cell_type":"code","metadata":{"id":"1ozXD-xYCcrT","executionInfo":{"status":"ok","timestamp":1633526270193,"user_tz":180,"elapsed":4365,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}}},"source":["import random\n","import torch\n","import torch.nn.functional as F\n","import numpy as np"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wHeZ9nAOEB0U","executionInfo":{"status":"ok","timestamp":1633526270708,"user_tz":180,"elapsed":527,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"6f959bbf-f6ad-4192-ea8b-3bbeb98040d1"},"source":["random.seed(123)\n","np.random.seed(123)\n","torch.manual_seed(123)"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f3d377b4e70>"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"CXFdJz2KVeQw"},"source":["## Preparando Dados"]},{"cell_type":"markdown","metadata":{"id":"gHMi_Kq65fPM"},"source":["Primeiro, fazemos download do dataset:"]},{"cell_type":"code","metadata":{"id":"2wbnfzst5O3k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633526291605,"user_tz":180,"elapsed":20901,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"5c079f31-7f2c-4226-be35-1641c1043882"},"source":["!wget -nc http://files.fast.ai/data/aclImdb.tgz \n","!tar -xzf aclImdb.tgz"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-10-06 13:17:50--  http://files.fast.ai/data/aclImdb.tgz\n","Resolving files.fast.ai (files.fast.ai)... 104.26.3.19, 104.26.2.19, 172.67.69.159, ...\n","Connecting to files.fast.ai (files.fast.ai)|104.26.3.19|:80... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://files.fast.ai/data/aclImdb.tgz [following]\n","--2021-10-06 13:17:50--  https://files.fast.ai/data/aclImdb.tgz\n","Connecting to files.fast.ai (files.fast.ai)|104.26.3.19|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 145982645 (139M) [application/x-gtar-compressed]\n","Saving to: ‘aclImdb.tgz’\n","\n","aclImdb.tgz         100%[===================>] 139.22M  21.3MB/s    in 6.9s    \n","\n","2021-10-06 13:17:57 (20.2 MB/s) - ‘aclImdb.tgz’ saved [145982645/145982645]\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"0Giyi5Rv_NIm"},"source":["## Carregando o dataset\n","\n","Criaremos uma divisão de treino (20k exemplos) e validação (5k exemplos) artificialmente."]},{"cell_type":"code","metadata":{"id":"0HIN_xLI_TuT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633526293098,"user_tz":180,"elapsed":1501,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"45f0e34a-fb81-4f2b-ce35-2a2651aca65c"},"source":["import os\n","\n","max_valid = 5000\n","\n","def load_texts(folder):\n","    texts = []\n","    for path in os.listdir(folder):\n","        with open(os.path.join(folder, path)) as f:\n","            texts.append(f.read())\n","    return texts\n","\n","x_train_pos = load_texts('aclImdb/train/pos')\n","x_train_neg = load_texts('aclImdb/train/neg')\n","x_test_pos = load_texts('aclImdb/test/pos')\n","x_test_neg = load_texts('aclImdb/test/neg')\n","\n","x_train = x_train_pos + x_train_neg\n","x_test = x_test_pos + x_test_neg\n","y_train = [True] * len(x_train_pos) + [False] * len(x_train_neg)\n","y_test = [True] * len(x_test_pos) + [False] * len(x_test_neg)\n","\n","# Embaralhamos o treino para depois fazermos a divisão treino/valid.\n","c = list(zip(x_train, y_train))\n","random.shuffle(c)\n","x_train, y_train = zip(*c)\n","\n","x_valid = x_train[-max_valid:]\n","y_valid = y_train[-max_valid:]\n","x_train = x_train[:-max_valid]\n","y_train = y_train[:-max_valid]\n","\n","print(len(x_train), 'amostras de treino.')\n","print(len(x_valid), 'amostras de desenvolvimento.')\n","print(len(x_test), 'amostras de teste.')\n","\n","print('3 primeiras amostras treino:')\n","for x, y in zip(x_train[:3], y_train[:3]):\n","    print(y, x[:100])\n","\n","print('3 últimas amostras treino:')\n","for x, y in zip(x_train[-3:], y_train[-3:]):\n","    print(y, x[:100])\n","\n","print('3 primeiras amostras validação:')\n","for x, y in zip(x_valid[:3], y_test[:3]):\n","    print(y, x[:100])\n","\n","print('3 últimas amostras validação:')\n","for x, y in zip(x_valid[-3:], y_valid[-3:]):\n","    print(y, x[:100])"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["20000 amostras de treino.\n","5000 amostras de desenvolvimento.\n","25000 amostras de teste.\n","3 primeiras amostras treino:\n","False Jill Dunne (played by Mitzi Kapture), is an attractive, nice woman, over-whelmed by a smart-mouthed \n","False The guy did a lot of title design for a bunch of movies and I guess one day he said; I should pick a\n","True A River Runs Through It is one of those movies that deserves to be seen in the theater so that the m\n","3 últimas amostras treino:\n","False We now travel to a parallel universe where the appearance of giant prehistoric monsters flattening c\n","True Maria Braun is an extraordinary woman presented fully and very credibly, despite being so obtuse as \n","True Mel Torme and Victor Borge, in their younger years, serve to make this film interesting - and especi\n","3 primeiras amostras validação:\n","True While returning from a Christmas Eve shopping trip, an abused suburban housewife (Basinger) finds he\n","True Man, some of you people have got to chill. This movie was artistic genius. Instead of searching for \n","True Before the Internet this movie could never have been made but the idea that the Web is full of evil \n","3 últimas amostras validação:\n","True This amazing Oscar winner (4 in total) and John Ford's first Academy Award winner, is simply spellbi\n","True Since it has been some years since I reviewed this classic I have decided to go back and review it m\n","True Sometimes they get lucky and have a hit on their hands (Wayne's World, the first one, not the second\n"]}]},{"cell_type":"markdown","metadata":{"id":"0c_-4MRtsOL_"},"source":["# Carregando os embeddings do Glove"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A5h_a9nvs5FJ","executionInfo":{"status":"ok","timestamp":1633526479391,"user_tz":180,"elapsed":186299,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"1acb4a63-67b7-4386-a646-aed54f2b17ed"},"source":["!wget -nc http://nlp.stanford.edu/data/glove.6B.zip\n","!unzip -o glove.6B.zip -d glove_dir"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-10-06 13:18:12--  http://nlp.stanford.edu/data/glove.6B.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n","--2021-10-06 13:18:13--  https://nlp.stanford.edu/data/glove.6B.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n","--2021-10-06 13:18:13--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n","Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n","Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 862182613 (822M) [application/zip]\n","Saving to: ‘glove.6B.zip’\n","\n","glove.6B.zip        100%[===================>] 822.24M  5.00MB/s    in 2m 41s  \n","\n","2021-10-06 13:20:54 (5.12 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n","\n","Archive:  glove.6B.zip\n","  inflating: glove_dir/glove.6B.50d.txt  \n","  inflating: glove_dir/glove.6B.100d.txt  \n","  inflating: glove_dir/glove.6B.200d.txt  \n","  inflating: glove_dir/glove.6B.300d.txt  \n"]}]},{"cell_type":"code","metadata":{"id":"D9NSvROYvnWY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633526531440,"user_tz":180,"elapsed":52074,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"64dab1c3-a3b0-4f56-9227-d79d6a7b16e7"},"source":["from torchtext.vocab import GloVe\n","glove_vectors = GloVe(name='6B', dim=300, cache='./glove_dir')"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 399999/400000 [00:47<00:00, 8450.97it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"dz4RNqJ3wNzn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633526531447,"user_tz":180,"elapsed":34,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"5aa6c4be-1c50-4aca-eed9-baf14f490519"},"source":["print(glove_vectors.vectors.shape)\n","print('Primeiras 20 palavras e seus índices:', list(glove_vectors.stoi.items())[:20])"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([400000, 300])\n","Primeiras 20 palavras e seus índices: [('the', 0), (',', 1), ('.', 2), ('of', 3), ('to', 4), ('and', 5), ('in', 6), ('a', 7), ('\"', 8), (\"'s\", 9), ('for', 10), ('-', 11), ('that', 12), ('on', 13), ('is', 14), ('was', 15), ('said', 16), ('with', 17), ('he', 18), ('as', 19)]\n"]}]},{"cell_type":"code","metadata":{"id":"1ySaZBHxTLFa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633526531448,"user_tz":180,"elapsed":21,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"dde92480-7ea8-4de9-e4b3-c30dd322f416"},"source":["vocab = glove_vectors.stoi\n","vocab['<UNK>'] = params['vocabulary_size'] # The last row is for the unknown token.\n","\n","# We create a random vector for the unknown token\n","unk_vector = torch.FloatTensor(1, glove_vectors.vectors.shape[1]).uniform_(-0.5, 0.5)\n","\n","# We create a vector of zeros for the pad token\n","pad_vector = torch.zeros(1, glove_vectors.vectors.shape[1])\n","\n","# And add them to the embeddings matrix.\n","embeddings = torch.cat((glove_vectors.vectors, unk_vector, pad_vector), dim=0)\n","\n","print(f'Total de palavras: {len(vocab)}')\n","print(f'embeddings.shape: {embeddings.shape}')"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Total de palavras: 400001\n","embeddings.shape: torch.Size([400002, 300])\n"]}]},{"cell_type":"markdown","metadata":{"id":"XLlaPgP0Z_D4"},"source":["# Definindo o tokenizador"]},{"cell_type":"code","metadata":{"id":"YIpp1C_qZ-QX","executionInfo":{"status":"ok","timestamp":1633526531448,"user_tz":180,"elapsed":13,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}}},"source":["import collections\n","import re\n","\n","\n","def tokenize(text):\n","    return [token.lower() for token in re.compile('\\w+').findall(text)]\n","\n","\n","def to_token_ids(text, vocab, max_length, padding_idx):\n","    tokens = tokenize(text)[:max_length]  # Truncating.\n","    token_ids = []\n","    for token in tokens:\n","        # We use the id of the \"<UNK>\" token if we don't find it in the vocabulary.\n","        token_id = vocab.get(token, vocab['<UNK>'])\n","        token_ids.append(token_id)\n","\n","    # Adding PAD tokens, if necessary.\n","    token_ids += [padding_idx] * max(0, max_length - len(token_ids))\n","    return token_ids"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7_6pddDHEM_r"},"source":["## Definindo o Modelo"]},{"cell_type":"code","metadata":{"id":"oLReRSuDEPLL","executionInfo":{"status":"ok","timestamp":1633526531810,"user_tz":180,"elapsed":374,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}}},"source":["# É recomendado reiniciar as seeds antes de inicializar o modelo, pois assim\n","# garantimos que os pesos vao ser sempre os mesmos.\n","import math\n","random.seed(123)\n","np.random.seed(123)\n","torch.manual_seed(123)\n","\n","class SelfAttentionLayer(torch.nn.Module):\n","\n","\n","    def __init__(self, embeddings, padding_idx, n_heads, dim, max_length):\n","        super().__init__()\n","        # Escreva o codigo aqui.\n","        # É importante que as camadas seja criadas na ordem abaixo, para\n","        # garantimos que terão os mesmos pesos usados para criar o vetor target\n","        # usado nos asserts:\n","\n","        self.n_heads = n_heads\n","        self.dim = dim\n","        self.max_length = max_length\n","        self.padding_idx = padding_idx\n","        self.dim_div_head = dim//n_heads\n","        self.h_ff = dim\n","\n","        self.embedding_layer = torch.nn.Embedding.from_pretrained(\n","                                embeddings, \n","                                freeze=True, \n","                                padding_idx=padding_idx)\n","\n","        self.positional_embeddings = self.get_positional_embeddings(max_length, dim)\n","\n","        self.W_q = torch.nn.Linear(dim, dim, bias = False)\n","        self.W_k = torch.nn.Linear(dim, dim, bias = False)\n","        self.W_v = torch.nn.Linear(dim, dim, bias = False)\n","        self.W_o = torch.nn.Linear(dim, dim, bias = False)\n","\n","        self.layer_norm1 = torch.nn.LayerNorm(self.dim, eps=1e-6) #(create with eps=1e-6)\n","\n","        self.feed_forward = torch.nn.Sequential(\n","            torch.nn.Linear(dim, self.h_ff),\n","            torch.nn.ReLU(),\n","            torch.nn.Linear(self.h_ff, dim)\n","        ) #(2 layers with a ReLU in-between) \n","\n","        self.layer_norm2 = torch.nn.LayerNorm(self.dim, eps=1e-6) #(create with eps=1e-6)\n","\n","\n","    def get_positional_embeddings(self, max_length, dim):\n","      # positional_embeds = torch.zeros(max_length,dim)\n","      # for pos in range(max_length):\n","      #   for i in range(0, dim, 2):\n","      #     positional_embeds[pos, i] = math.sin(pos / (10000**(2*i/dim)))\n","      #     positional_embeds[pos, i+1] = math.cos(pos / (10000**(2*(i+1)/dim)))\n","      positional_embeds = torch.nn.Parameter(torch.rand(max_length, dim))\n","      return positional_embeds\n","\n","    def forward(self, batch_token_ids):\n","        # Escreva o codigo aqui.\n","\n","        batch_seqs =  self.embedding_layer(batch_token_ids) # shape = B, L, D\n","\n","        positional_att = batch_seqs + self_attention_layer.positional_embeddings # shape = B, L, D\n","\n","        #mask\n","        pad_mask = (batch_token_ids != self.padding_idx).unsqueeze(1)\n","\n","        x = positional_att\n","\n","        x = self.layer_norm1(x + self.multihead_attention(x, pad_mask)) # shape = B, L, D\n","        x = self.layer_norm2(x + self.feed_forward(x)) # shape = B, L, D\n","\n","        return x.mean(1)\n","\n","    def multihead_attention(self, positional_att, pad_mask):\n","\n","      batch_size = positional_att.shape[0]\n","\n","      q = self.W_q(positional_att).reshape(batch_size, self.max_length, self.n_heads, self.dim_div_head) # shape = B, L, H, D/H\n","      k = self.W_k(positional_att).reshape(batch_size, self.max_length, self.n_heads, self.dim_div_head)\n","      v = self.W_v(positional_att).reshape(batch_size, self.max_length, self.n_heads, self.dim_div_head)\n","\n","      # q = k = v = positional_att.reshape(batch_size, self.max_length, self.n_heads, self.dim_div_head)\n","\n","      q, k, v = q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2) # shape = B, H, L, D/H\n","\n","      new_x = self.attention(q, k, v, pad_mask)    # new_x.shape = B, H, L, D/H\n","\n","      new_x = new_x.transpose(1, 2).contiguous()  # new_x.shape = B, L, H, D/H\n","      new_x = new_x.reshape(batch_size, self.max_length, self.dim)\n","\n","      return self.W_o(new_x)\n","\n","    def attention(self, q, k, v, mask):\n","      scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.dim)\n","\n","      # B, L -> B, 1, L -> B, L, L\n","      pad_mask_expanded = mask[:, None, :, :].expand_as(scores)\n","      scores.masked_fill_(~pad_mask_expanded, float('-inf'))  # B, L, L\n","\n","      probs = F.softmax(scores, dim=-1) # shape = B, L, L\n","      E = torch.matmul(probs, v)\n","\n","      return E\n","\n","\n","# self_attention_layer = SelfAttentionLayer(\n","#   embeddings=fake_embeddings,\n","#   padding_idx=4,\n","#   dim=2,\n","#   n_heads=2,\n","#   max_length=2)\n","# my_output = self_attention_layer(batch_token_ids[:])\n","# my_output#.mean(1)"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MSbNNLzjya7z"},"source":["## Testando a implementação com embeddings \"falsos\""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7K_LJm2lygau","executionInfo":{"status":"ok","timestamp":1633526531811,"user_tz":180,"elapsed":23,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"5c29908d-a12a-4352-fb94-676db006f03f"},"source":["fake_vocab = {\n","    'a': 0,\n","    'b': 1,\n","    'c': 2,\n","    '<UNK>': 3 \n","}\n","\n","fake_embeddings = torch.arange(0, 2 * len(fake_vocab)).reshape(len(fake_vocab), 2).float()\n","pad_vector = torch.zeros(1, 2)\n","fake_embeddings = torch.cat((fake_embeddings, pad_vector), dim=0)\n","\n","fake_examples = [\n","    'a', # Testing PAD\n","    'a b',\n","    'a c b', # Testing truncation\n","    'a z', # Testing <UNK>\n","    ]\n","\n","print(f'Total de palavras: {len(fake_vocab)}')\n","print(f'embeddings.shape: {fake_embeddings.shape}')"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Total de palavras: 4\n","embeddings.shape: torch.Size([5, 2])\n"]}]},{"cell_type":"code","metadata":{"id":"0IHiV6nRzg4q","executionInfo":{"status":"ok","timestamp":1633526531812,"user_tz":180,"elapsed":16,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}}},"source":["self_attention_layer = SelfAttentionLayer(\n","    embeddings=fake_embeddings,\n","    padding_idx=4,\n","    dim=2,\n","    n_heads=2,\n","    max_length=2)\n","\n","batch_token_ids = []\n","for example in fake_examples:\n","    token_ids = to_token_ids(\n","        text=example,\n","        vocab=fake_vocab,\n","        max_length=2,\n","        padding_idx=4)\n","    batch_token_ids.append(token_ids)\n","\n","batch_token_ids = torch.LongTensor(batch_token_ids)\n","my_output = self_attention_layer(batch_token_ids)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"gFF0AkR74Drr","executionInfo":{"status":"ok","timestamp":1633526531813,"user_tz":180,"elapsed":17,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}}},"source":["torch.set_printoptions(precision=10)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"2RMkzafh1nkk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633526531813,"user_tz":180,"elapsed":16,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"59cefbc3-07f7-47db-99e3-6038d9f07c40"},"source":["my_output"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.9999976158,  0.9999976158],\n","        [-0.9999976158,  0.9999975562],\n","        [-0.9999974966,  0.9999974966],\n","        [-0.9999975562,  0.9999974966]], grad_fn=<MeanBackward1>)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"zJsMGZ911l67","executionInfo":{"status":"ok","timestamp":1633526531815,"user_tz":180,"elapsed":14,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}}},"source":["target_output = torch.FloatTensor([\n","    [-0.9999975562,  0.9999975562],\n","    [-0.9999975562,  0.9999976158],\n","    [-0.9999975562,  0.9999974966],\n","    [-0.9999974966,  0.9999974966]])"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"IR_sjMsm1kK1","executionInfo":{"status":"ok","timestamp":1633526531816,"user_tz":180,"elapsed":13,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}}},"source":["assert torch.allclose(my_output, target_output, atol=1e-8)"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XS6p45y4It01"},"source":["## Testando a implementação com 8 exemplos do dataset do IMDB"]},{"cell_type":"code","metadata":{"id":"dm_WeJi-EciW"},"source":["examples = [\n","    \"THE TEMP (1993) didn't do much theatrical business, but here's the direct-to-video rip-off you didn't want, anyway! Ellen Bradford (Mel Harris) is the new woman at Millennium Investments, a high scale brokerage firm, who starts getting helpful hints from wide-eyed secretary Deidre (Sheila Kelley). Deidre turns out to be an ambitious daddy's girl who will stop at nothing to move up the corporate ladder, including screwing a top broker she can't stand and murdering anyone who gets on her bad side. She digs up skeletons in Ellen's closet, tries to cause problems with her husband (Barry Bostwick), kills while making it look like she is responsible, kidnaps her daughter and tries to get her to embezzle money from the company.<br /><br />Harris and Kelley deliver competent performances, the supporting cast is alright and it's reasonably well put-together, but that doesn't fully compensate for a script that travels down a well-worn path and offers few surprises.\",\n","    \"Sondra Locke stinks in this film, but then she was an awful 'actress' anyway. Unfortunately, she drags everyone else (including then =real life boyfriend Clint Eastwood down the drain with her. But what was Clint Eastwood thinking when he agreed to star in this one? One read of the script should have told him that this one was going to be a real snorer. It's an exceptionally weak story, basically no story or plot at all. Add in bored, poor acting, even from the normally good Eastwood. There's absolutely no action except a couple arguments and as far as I was concerned, this film ranks up at the top of the heap of natural sleep enhancers. Wow! Could a film BE any more boring? I think watching paint dry or the grass grow might be more fun. A real stinker. Don't bother with this one.\",\n","    \"Judy Davis shows us here why she is one of Australia's most respected and loved actors - her portrayal of a lonely, directionless nomad is first-rate. A teenaged Claudia Karvan also gives us a glimpse of what would make her one of this country's most popular actors in years to come, with future roles in THE BIG STEAL, THE HEARTBREAK KID, DATING THE ENEMY, RISK and the acclaimed TV series THE SECRET LIFE OF US. (Incidentally, Karvan, as a child, was a young girl whose toy Panda was stolen outside a chemist's shop in the 1983 drama GOING DOWN with Tracey Mann.) If this films comes your way, make sure you see it!! Rating: 79/100. See also: HOTEL SORRENTO, RADIANCE, VACANT POSSESSION, LANTANA.\",\n","    'New York playwright Michael Caine (as Sidney Bruhl) is 46-years-old and fading fast; as the film opens, Mr. Caine\\'s latest play flops on Broadway. TV reviewers poke fun at Caine, and he gets drunk. Passing out on the Long Island Railroad lands Caine in Montauk, instead of his residence in East Hampton. Finally arriving home, Caine is comforted by tightly-attired wife Dyan Cannon (as Myra), an unfortunately high-strung heart patient. There, Caine and Ms. Cannon discuss a new play called \"Deathtrap\", written by hunky young Christopher Reeve (as Clifford \"Cliff\" Anderson), one of Caine\\'s former students. The couple believe Mr. Reeve\\'s \"Deathtrap\" is the hit needed to revive Caine\\'s career.<br /><br />\"The Trap Is Set\\x85 For A Wickedly Funny Who\\'ll-Do-It.\" <br /><br />Directed by Sidney Lumet, Ira Levin\\'s long-running Broadway hit doesn\\'t stray too far from its stage origin. The cast is enjoyable and the story\\'s twists are still engrossing. One thing that did not work (for me) was the curtain call ending; surely, it played better on stage. \"Deathtrap\" is a fun film to watch again; the performances are dead on - but, in hindsight, the greeting Reeve gives Caine at the East Hampton train station should have been simplified to a smiling \"Hello.\" The location isn\\'t really East Hampton, but the windmill and pond look similar. And, the much ballyhooed love scene is shockingly tepid. But, the play was so good, \"even a gifted director couldn\\'t ruin it.\" And, Mr. Lumet doesn\\'t disappoint.<br /><br />******** Deathtrap (3/19/82) Sidney Lumet ~ Michael Caine, Christopher Reeve, Dyan Cannon, Irene Worth',\n","    'Students often ask me why I choose this version of Othello. Shakespeare\\'s text is strongly truncated and the film contains material which earned it an \"R\" rating.<br /><br />I have several reasons for using this production: First, I had not seen a depiction of the Moor that actually made me sympathetic to Othello until I saw Fishburne play him. I saw James Earl Jones and Christopher Plummer play Othello and Iago on Broadway, and it was wonderful. Plummer\\'s energy was especially noticeable. But in spite of Jone\\'s incredible presence both physically and vocally, the character he played just seemed too passive to illicit from me a complete emotional purgation in the Aristotelian sense. Jones, in fact, affirmed what I felt when in an interview he noted that he had played Othello as passive--seeing Iago as basically doing him over. Unfortunately this sapped my grief for the character destruction. Thus, I felt sympathy for Jone\\'s Moor but not the horror over his corruption by an evil man. In contrast, Fishburne\\'s Othello is a strong and vigorous figure familiar with taking action. Thus, Iago\\'s temptation to actively deal with what is presented to Othello as his wife\\'s unfaithfulness is a perversion of the general\\'s positive quality to be active not passive.1 The horror of the story is that this good quality in Othello becomes perverted. Fishburne\\'s depiction is therefore classically tragic.<br /><br />Second, Fishburne is the first black actor to play Othello in a film. Both Orsen Wells and Anthony Hopkins did fine film versions, but they were white men in black face.2 Why is this important? Why should a Black actor be the Black man on the stage?3 Certainly in Shakespeare\\'s day they used black face just as they used boys to make girls. Perhaps then, the reason is the same. Female actors bring a special quality to female roles on the Shakespearian stage because they understand best what Shakespeare\\'s genius was trying to present. A gifted black actor should play the moor because his experience in a white dominated culture is vital to understanding what Shakespeare\\'s genius recognized: the pain of being marginalized because of race. An important theme in Othello is isolation caused by racism. Although it is a mistake to insert American racism into a Shakespearian play, there can be little doubt that racism is still working among the characters. Many, including Desdimona\\'s father, think that a union between a Venetian white Christian woman and a North African black Christian man is UNNATURAL.<br /><br />Third, Shakespeare was never G rated. He never has been. His stage productions were always typified by violence and strong language. But Shakespeare\\'s genius uses these elements not as sensationialism but for artistic honesty.',\n","    'Roeg has done some great movies, but this a turkey. It has a feel of a play written by an untalented high-school student for his class assignment. The set decoration is appealing in a somewhat surrealistic way, but the actual story is insufferable hokum.',\n","    \"<br /><br />What is left of Planet Earth is populated by a few poor and starving rag-tag survivors. They must eat bugs and insects, or whatever, after a poison war, or something, has nearly wiped out all human civilization. In these dark times, one of the few people on Earth still able to live in comfort, we will call him the All Knowing Big Boss, has a great quest to prevent some secret spore seeds from being released into the air. It seems that the All Knowing Big Boss is the last person on Earth that knows that these spores even exist. The spores are located far away from any living soul, and they are highly protected by many layers of deadly defense systems. <br /><br />The All Knowing Big Boss wants the secret spores to remain in their secret protected containers. So, he makes a plan to send in a macho action team to remove the spore containers from all of the protective systems and secret location. Sending people to the location of secret spores makes them no longer a secret. Sending people to disable all of the protective systems makes it possible for the spores to be easily released into the air. How about letting sleeping dogs lie?! <br /><br />The one pleasant feature of ENCRYPT is the radiant and elegant Vivian Wu. As the unremarkable macho action team members drop off with mechanically paced predictable timing, engaging Vivian Wu's charm makes acceptable the plot idea of her old employer wanting her so much. She is an object of love, an object of desire -- a very believable concept!<br /><br />Fans of Vivian Wu may want to check out an outstanding B-movie she is in from a couple years back called DINNER RUSH. DINNER RUSH is highly recommended. ENCRYPT is not.\",\n","    \"So the other night I decided to watch Tales from the Hollywood Hills: Natica Jackson. Or Power, Passion, Murder as it is called in Holland. When I bought the film I noticed that Michelle Pfeiffer was starring in it and I thought that had to say something about the quality. Unfortunately, it didn't.<br /><br />1) The plot of the film is really confusing. There are two story lines running simultaneously during the film. Only they have nothing in common. Throughout the entire movie I was waiting for the moment these two story lines would come together so the plot would be clear to me. But it still hasn't.<br /><br />2) The title of the film says the film will be about Natica Jackson. Well it is, sometimes. Like said the film covers two different stories and the part about Natica Jackson is the shortest. So another title for this movie would not be a wrong choice.<br /><br />To conclude my story, I really recommend that you leave this movie where it belongs, on the shelf in the store on a place nobody can see it. By doing this you won't waste 90 minutes of your life, as I did.\"         \n","]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"glpuB87bI1_X"},"source":["# random.seed(123)\n","# np.random.seed(123)\n","# torch.manual_seed(123)\n","self_attention_layer = SelfAttentionLayer(\n","    embeddings=embeddings,\n","    padding_idx=params['padding_idx'],\n","    dim=params['dim'],\n","    n_heads=params['n_heads'],\n","    max_length=params['max_length'])\n","\n","batch_token_ids = []\n","for example in examples:\n","    token_ids = to_token_ids(\n","        text=example,\n","        vocab=vocab,\n","        max_length=params['max_length'],\n","        padding_idx=params['padding_idx'])\n","    batch_token_ids.append(token_ids)\n","\n","batch_token_ids = torch.LongTensor(batch_token_ids)\n","my_output = self_attention_layer(batch_token_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iReQTvGrntNh","executionInfo":{"status":"ok","timestamp":1633524930157,"user_tz":180,"elapsed":17,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"8ba6a3fe-85bc-4454-fbb7-bdd6d0bad503"},"source":["my_output"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.0176682044, -0.0533530153, -0.5168266892,  ...,\n","         -0.0433933102, -0.3407097757,  0.8297407031],\n","        [ 0.0406439975, -0.0057798605, -0.3925316930,  ...,\n","         -0.1165959910, -0.4028465152,  0.6854071021],\n","        [ 0.0903515071, -0.0329397395, -0.4079618454,  ...,\n","          0.0144704888, -0.4582284093,  0.7111889720],\n","        ...,\n","        [ 0.1839060187, -0.0195308533, -0.5238590837,  ...,\n","         -0.0809618160, -0.4240354896,  0.5491316319],\n","        [-0.0878479555,  0.0243917890, -0.3642489910,  ...,\n","         -0.2380990982, -0.5123932362,  0.4910638332],\n","        [ 0.0254464466, -0.0258459616, -0.3857077360,  ...,\n","         -0.2584770918, -0.3513222933,  0.6415528655]],\n","       grad_fn=<MeanBackward1>)"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"N0VUv1A_r5oO"},"source":["Fazemos o download do tensor esperado e o comparamos com nossa saída"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"THva0R6h6A_e","executionInfo":{"status":"ok","timestamp":1633524930692,"user_tz":180,"elapsed":548,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"ecce8d2a-701b-49af-dd37-d89a365cc219"},"source":["!wget https://storage.googleapis.com/neuralresearcher_data/unicamp/ia376e_2021s2/aula8/target_tensor.pt"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-10-06 12:55:30--  https://storage.googleapis.com/neuralresearcher_data/unicamp/ia376e_2021s2/aula8/target_tensor.pt\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.137.128, 142.250.101.128, 142.250.141.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.137.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 10347 (10K) [application/octet-stream]\n","Saving to: ‘target_tensor.pt’\n","\n","\rtarget_tensor.pt      0%[                    ]       0  --.-KB/s               \rtarget_tensor.pt    100%[===================>]  10.10K  --.-KB/s    in 0s      \n","\n","2021-10-06 12:55:30 (81.7 MB/s) - ‘target_tensor.pt’ saved [10347/10347]\n","\n"]}]},{"cell_type":"code","metadata":{"id":"p2C1ZvxoAkCN"},"source":["target_output = torch.load('target_tensor.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1RNPTGnCLGBl","colab":{"base_uri":"https://localhost:8080/","height":163},"executionInfo":{"status":"error","timestamp":1633524931067,"user_tz":180,"elapsed":398,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"f6b561ba-e89f-4d7d-8130-7d8193c61df8"},"source":["assert torch.allclose(my_output, target_output, atol=1e-6)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"AssertionError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-5483ecf26791>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAssertionError\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"ORRH_fU6dhTH"},"source":["## Configuração do Dataset + DataLoader"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X-JZiH70dgvj","executionInfo":{"status":"ok","timestamp":1633526532050,"user_tz":180,"elapsed":246,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"929fa885-ace6-4b43-f8a8-cebf7fdc750d"},"source":["from torch import nn\n","from torch.utils.data import DataLoader, Dataset\n","\n","class IMDB(Dataset):\n","  def __init__(self, texts, y, vocabulary, padding_idx, max_length):\n","    self.y = y\n","    self.x = np.array([to_token_ids(text, vocabulary, max_length, padding_idx) for text in texts])\n","\n","  def __len__(self):\n","    return len(self.x)\n","\n","  def __getitem__(self, idx):\n","    return self.x[idx], self.y[idx]\n","\n","def get_dataloader(texts, y, vocabulary, batch_size):\n","  dataset = IMDB(texts, y, vocabulary, params['padding_idx'], params['max_length'])\n","  dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","  return dataloader\n","\n","train_dataloader = get_dataloader(x_train[:10], y_train[:10], vocab, 16)\n","next(iter(train_dataloader))"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[tensor([[  1251,     15,      0,  ..., 400001, 400001, 400001],\n","         [    22,     58,  10145,  ..., 400001, 400001, 400001],\n","         [    37,    591,   2949,  ...,      0,    921,      3],\n","         ...,\n","         [     0,   1417,   6395,  ...,  30879,     46,     26],\n","         [   192,    702,     14,  ...,    246,    858,      6],\n","         [    49,    518,    541,  ..., 400001, 400001, 400001]]),\n"," tensor([False, False,  True, False,  True, False,  True,  True,  True, False])]"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"_Dvgor6Wf-zf"},"source":["# Criação da rede"]},{"cell_type":"code","metadata":{"id":"XY4p3pe6f-EK","executionInfo":{"status":"ok","timestamp":1633526532051,"user_tz":180,"elapsed":8,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}}},"source":["import torch.nn.functional as F\n","\n","class SelfAttentionModel(nn.Module):\n","  def __init__(self, embeddings, padding_idx, dim, n_heads, max_length):\n","    super(SelfAttentionModel, self).__init__()\n","    self.attention = SelfAttentionLayer(    \n","                                      embeddings=embeddings,\n","                                      padding_idx=params['padding_idx'],\n","                                      dim=dim,\n","                                      n_heads=n_heads,\n","                                      max_length=max_length,\n","                                      )\n","    self.linear = torch.nn.Sequential(\n","                                       nn.Linear(300, 128),\n","                                       nn.Tanh(),\n","                                       nn.Linear(128,2)\n","                                      )\n","\n","  def forward(self, input):\n","    att = self.attention(input)\n","    out = self.linear(att)\n","    return out\n","\n","# def init_weights(m):\n","#   if isinstance(m, nn.Linear):\n","#       torch.nn.init.xavier_uniform_(m.weight)\n","\n","att_model = SelfAttentionModel(embeddings=embeddings, padding_idx=params['padding_idx'], dim=params['dim'], n_heads=params['n_heads'], max_length=params['max_length'])\n","# att_model.apply(init_weights)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZcDubQpamgZC","executionInfo":{"status":"ok","timestamp":1633526532051,"user_tz":180,"elapsed":8,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}}},"source":["x,y = next(iter(train_dataloader))"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":306},"id":"d8sSwvgljBk2","executionInfo":{"status":"error","timestamp":1633526788494,"user_tz":180,"elapsed":228,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"198f5c0a-8bf1-4067-d879-8f4bb8212c29"},"source":["att_model(x)"],"execution_count":24,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-24cd7a969cb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0matt_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-f87480fc60e6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0matt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-fe1ce677fcec>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch_token_ids)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mbatch_seqs\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_token_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# shape = B, L, D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mpositional_att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_seqs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself_attention_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositional_embeddings\u001b[0m \u001b[0;31m# shape = B, L, D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m#mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (300) must match the size of tensor b (2) at non-singleton dimension 2"]}]},{"cell_type":"markdown","metadata":{"id":"isvpd46jmsbB"},"source":["# Configurações globais"]},{"cell_type":"code","metadata":{"id":"ps6DEQtWmruk","executionInfo":{"status":"aborted","timestamp":1633526532293,"user_tz":180,"elapsed":13,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}}},"source":["learning_rate = 0.001\n","epochs = 100\n","criterion = nn.CrossEntropyLoss()\n","batch_size = 64\n","\n","params_log = {\"learning_rate\": learning_rate,\n","          \"optimizer\": \"Adam\",\n","          \"batch_size\":batch_size}\n","\n","#optimizer = torch.optim.Adam(att_model.parameters(), lr=learning_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JYsny6mdm0N8"},"source":["## Funçoes de treino e teste"]},{"cell_type":"code","metadata":{"id":"f-16LEspmztw","executionInfo":{"status":"aborted","timestamp":1633526532295,"user_tz":180,"elapsed":15,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}}},"source":["def test(model, dataloader, criterion):\n","  model.eval()\n","  size = len(dataloader.dataset)\n","  num_batches = len(dataloader)\n","  loss = 0\n","  correct = 0.0\n","  for i, data in enumerate(dataloader):\n","    x,y = data\n","    x = x.to(device)\n","    y = y.to(device)\n","    with torch.no_grad():\n","      logits = model(x)\n","      loss += criterion(logits, y.long()).item()\n","      correct += (logits.argmax(1) == y.long()).type(torch.float).sum().item()\n","  print(f\"Loss: {loss/num_batches}, Acc: {100*correct/size}\")\n","  return loss/num_batches, correct/size\n","\n","# test(model, val_dataloader, criterion)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kM4d3IOdm4ep","executionInfo":{"status":"aborted","timestamp":1633526532296,"user_tz":180,"elapsed":15,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}}},"source":["import matplotlib.pyplot as plt\n","\n","def train(model, train_dataloader, val_dataloader, epochs, criterion, optimizer, model_name):\n","  losses = []\n","  patience = 0\n","  best_loss = 1e10\n","  for epoch in range(epochs):\n","    model.train()\n","    print(f\"Epoch: {epoch}\")\n","    size = len(train_dataloader)\n","    for i, data in enumerate(train_dataloader):\n","      x,y = data\n","      x = x.to(device)\n","      y = y.to(device)\n","\n","      logits = model(x)\n","\n","      loss = criterion(logits, y.long())\n","\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","      '''\n","      if i % 50 == 0:\n","        run[\"train/loss\"].log(loss)\n","      '''\n","      if i % 100 == 0:\n","        print(f\"Batch: {i}/{size}\")\n","\n","    val_loss, val_acc = test(model, val_dataloader, criterion)\n","\n","    # run[\"val/loss\"].log(val_loss)\n","    # run[\"val/accuracy\"].log(val_acc)\n","    \n","    losses.append(val_loss)\n","    plt.plot(losses)\n","    if (round(best_loss,5) > round(val_loss, 5)):\n","      patience = 0\n","      best_loss = val_loss\n","      torch.save(model, f'{model_name}.pth')\n","    else:\n","      patience += 1\n","      if patience > 0:\n","        break\n","\n","# train(model, train_dataloader, val_dataloader, 1, criterion, optimizer)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v4Qa2QQAm6vX"},"source":["# Gerando datasets + treino do modelo com logging"]},{"cell_type":"code","metadata":{"id":"eeRtwSwam6Lo","executionInfo":{"status":"aborted","timestamp":1633526532297,"user_tz":180,"elapsed":17,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","att_model = att_model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lrSAshvtm-70","executionInfo":{"status":"aborted","timestamp":1633526532299,"user_tz":180,"elapsed":18,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}}},"source":["train_dataloader = get_dataloader(x_train,y_train, vocab,batch_size)\n","val_dataloader = get_dataloader(x_valid,y_valid, vocab,batch_size)\n","test_dataloader = get_dataloader(x_test,y_test, vocab,batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S8jxMs3TnIk4","executionInfo":{"status":"aborted","timestamp":1633526532300,"user_tz":180,"elapsed":19,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}}},"source":["'''\n","run = neptune.init(\n","    project=\"e166690/attention\",\n","    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIyNDBmMThjNi1kODM2LTQzYTItYTgzMi01YTczMjI3NjhjYTUifQ==\",\n",")\n","params.update({'model':'transformer_model'})\n","run[\"parameters\"] = params\n","'''\n","optimizer = torch.optim.Adam(att_model.parameters(), lr=learning_rate)\n","train(att_model, train_dataloader, val_dataloader, 10, criterion, optimizer, 'transformer_model')\n","# run.stop()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zJtmIiq_wjDw"},"source":["# Testando o modelo"]},{"cell_type":"code","metadata":{"id":"ZxZKj8qJwidY"},"source":["att_model = torch.load('transformer_model.pth')\n","test_loss, test_acc = test(att_model, test_dataloader, criterion)"],"execution_count":null,"outputs":[]}]}