{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Aula 9 - Guilherme Pereira","provenance":[{"file_id":"1jdMj1suHtikKs5UnpytK1lJ9bvRDHByx","timestamp":1634136478081},{"file_id":"1LpaixNlF2QrDplSrspxAWFgF6URbMz61","timestamp":1633455500099},{"file_id":"1qBaqEKlcy1Mnyhw_HKPgS-m45V8Ze2Mk","timestamp":1632932817064},{"file_id":"1iKPwoL-PtmJu0rpy1K0P4dqwZR44uDdL","timestamp":1632679088569},{"file_id":"1iCUWoyLkNU1-UmsB8YLfLvr3xwI04vIQ","timestamp":1632071575482},{"file_id":"1wpv_r96bBhIHJ3g9q3so3p8sHJ1HDk7H","timestamp":1631553851617},{"file_id":"1YW4O0K7EfSsgUe1kaZR9NswLXKVwqCb-","timestamp":1631389187602},{"file_id":"1Y3rRUiQGW5CEcPRkx_sfZGAEjNwVsw-b","timestamp":1631184728325},{"file_id":"1ONeS-lZ3vVqThueoTvQRMnZ_rJJB1yOl","timestamp":1629906878859}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"0862510d46b947f7bd7b22870845945f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f5725e0b1f9240f9ae8eb575b6d626d9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a752b61f3bfd4c2e8cc67422495450d6","IPY_MODEL_928bfbbce862444aa43686510473848c","IPY_MODEL_063018d6498742c59ca2a42b667bcb26"]}},"f5725e0b1f9240f9ae8eb575b6d626d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a752b61f3bfd4c2e8cc67422495450d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_eaf2a286420f4fbdb18b4763fb7623ae","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_55b10bceb5d14d7b8b3db70204250e76"}},"928bfbbce862444aa43686510473848c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_bfc3dda882354343ae1efefce8bbb1f8","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_636ff716645f4cafb4df015539d89ef2"}},"063018d6498742c59ca2a42b667bcb26":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5cf511c8c41542ffa06b6ba96fffefeb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 226k/226k [00:00&lt;00:00, 451kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2c64baa47f934e30b542b55157447a7e"}},"eaf2a286420f4fbdb18b4763fb7623ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"55b10bceb5d14d7b8b3db70204250e76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bfc3dda882354343ae1efefce8bbb1f8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"636ff716645f4cafb4df015539d89ef2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5cf511c8c41542ffa06b6ba96fffefeb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2c64baa47f934e30b542b55157447a7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d47f28abebf64f788d5a4e05928aabde":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_17a5c7f38b204ee1b30ef464b6edb4a2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_acc5a1dca510440b8690543b1b3f0968","IPY_MODEL_173f858160074df7a7e9a2dce9dfa310","IPY_MODEL_6ec7c303c990450499325345b12d7c06"]}},"17a5c7f38b204ee1b30ef464b6edb4a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"acc5a1dca510440b8690543b1b3f0968":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_69f7333a329b49939120d6886f038396","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a4133649790a41c497780d084b1eae55"}},"173f858160074df7a7e9a2dce9dfa310":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ce71745a169b423994e59a4c6826822b","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_02e27ea14bfe4c528d6e527c4b21b0c7"}},"6ec7c303c990450499325345b12d7c06":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_dc573b1acb8e4559b5c3d06eb272399e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 420M/420M [00:10&lt;00:00, 42.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7842ab52297b4abe93922c283c90f8fe"}},"69f7333a329b49939120d6886f038396":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a4133649790a41c497780d084b1eae55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ce71745a169b423994e59a4c6826822b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"02e27ea14bfe4c528d6e527c4b21b0c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dc573b1acb8e4559b5c3d06eb272399e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7842ab52297b4abe93922c283c90f8fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"1OG5DT_dm6mk"},"source":["# Notebook de referência \n","\n","Nome: Guilherme Pereira Albino da Silva RA: 182786"]},{"cell_type":"markdown","metadata":{"id":"LZ80hHaftwUd"},"source":["## Instruções:\n","\n","\n","Treinar e medir a acurácia de um modelo BERT (ou variantes) para classificação binária usando o dataset do IMDB (20k/5k amostras de treino/validação).\n","\n","Importante: \n","- Deve-se implementar o próprio laço de treinamento.\n","- Implementar o acumulo de gradiente.\n","\n","Dicas:\n","- BERT geralmente costuma aprender bem uma tarefa com poucas épocas (de 3 a 5 épocas). Se tiver demorando mais de 5 épocas para chegar em 80% de acurácia, ajuste os hiperparametros.\n","\n","- Solução para erro de memória:\n","  - Usar bfloat16 permite quase dobrar o batch size\n","\n","Opcional:\n","- Pode-se usar a função trainer da biblioteca Transformers/HuggingFace para verificar se seu laço de treinamento está correto. Note que ainda assim é obrigatório implementar o laço próprio.\n","\n","- Usar pytorch lightning. Para entender como o pytorch lightning funciona, veja uma implementação simplificada no notebook `06_01_Treino_Validação_MNIST_Lightning_Lite.ipynb`"]},{"cell_type":"markdown","metadata":{"id":"uhpAkifICdJo"},"source":["# Fixando a seed"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8wy6DVzRIOWO","executionInfo":{"status":"ok","timestamp":1634170353925,"user_tz":180,"elapsed":8212,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"ab2e855b-ade8-4d59-c4c2-8db3bf0e145c"},"source":["!pip install transformers"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 11.8 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 49.8 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 56.8 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n","Collecting huggingface-hub>=0.0.17\n","  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n","\u001b[K     |████████████████████████████████| 56 kB 4.6 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 42.0 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.19 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.11.3\n"]}]},{"cell_type":"code","metadata":{"id":"1ozXD-xYCcrT","executionInfo":{"status":"ok","timestamp":1634170418888,"user_tz":180,"elapsed":29880,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}}},"source":["import random\n","\n","import numpy as np\n","\n","from transformers import AutoTokenizer, BertForSequenceClassification, logging, BertTokenizer, DataCollatorWithPadding, AdamW\n","\n","import os\n","\n","from torch.utils.data import Dataset, DataLoader, dataloader\n","from torch import nn, Tensor\n","from torch.nn import CrossEntropyLoss\n","import torch.nn.functional as F\n","from torch.optim import Adam\n","\n","from tqdm.notebook import tqdm\n","\n","parametros = {'batch_size' : 32,\n","              'n_epochs'   : 3,\n","              'lr'         : 0.00005,\n","              'pretrained_model_name' : 'bert-base-uncased',\n","              'max_length' : 300\n","              }"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"wHeZ9nAOEB0U"},"source":["def reset_seed():\n","    random.seed(123)\n","    np.random.seed(123)\n","    torch.manual_seed(123)\n","    \n","reset_seed()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hiU6qzEaJMfg","executionInfo":{"status":"ok","timestamp":1634151773876,"user_tz":180,"elapsed":397,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"e1f0da76-0c7f-4cf0-816a-ef60479701d0"},"source":["if torch.cuda.is_available(): \n","    device = torch.device(\"cuda:0\")\n","    # print(torch. cuda. get_device_name(dev))\n","else: \n","    device = torch.device(\"cpu\")\n","print(device)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}]},{"cell_type":"markdown","metadata":{"id":"CXFdJz2KVeQw"},"source":["## Preparando Dados"]},{"cell_type":"markdown","metadata":{"id":"gHMi_Kq65fPM"},"source":["Primeiro, fazemos download do dataset:"]},{"cell_type":"code","metadata":{"id":"2wbnfzst5O3k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634170451634,"user_tz":180,"elapsed":26689,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"5b8c8fc9-da58-4d61-85b1-b5399fd0e335"},"source":["!wget -nc http://files.fast.ai/data/aclImdb.tgz \n","!tar -xzf aclImdb.tgz"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-10-14 00:13:43--  http://files.fast.ai/data/aclImdb.tgz\n","Resolving files.fast.ai (files.fast.ai)... 104.26.3.19, 104.26.2.19, 172.67.69.159, ...\n","Connecting to files.fast.ai (files.fast.ai)|104.26.3.19|:80... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://files.fast.ai/data/aclImdb.tgz [following]\n","--2021-10-14 00:13:43--  https://files.fast.ai/data/aclImdb.tgz\n","Connecting to files.fast.ai (files.fast.ai)|104.26.3.19|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 145982645 (139M) [application/x-gtar-compressed]\n","Saving to: ‘aclImdb.tgz’\n","\n","aclImdb.tgz         100%[===================>] 139.22M  11.5MB/s    in 13s     \n","\n","2021-10-14 00:13:57 (10.8 MB/s) - ‘aclImdb.tgz’ saved [145982645/145982645]\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"0Giyi5Rv_NIm"},"source":["## Carregando o dataset\n","\n","Criaremos uma divisão de treino (20k exemplos) e validação (5k exemplos) artificialmente."]},{"cell_type":"code","metadata":{"id":"0HIN_xLI_TuT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634170638627,"user_tz":180,"elapsed":1718,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"519865be-77dc-4b62-cd43-f525a0bed9bd"},"source":["import os\n","\n","max_valid = 5000\n","\n","def load_texts(folder):\n","    texts = []\n","    for path in os.listdir(folder):\n","        with open(os.path.join(folder, path)) as f:\n","            texts.append(f.read())\n","    return texts\n","\n","x_train_pos = load_texts('aclImdb/train/pos')\n","x_train_neg = load_texts('aclImdb/train/neg')\n","x_test_pos = load_texts('aclImdb/test/pos')\n","x_test_neg = load_texts('aclImdb/test/neg')\n","\n","x_train = x_train_pos + x_train_neg\n","x_test = x_test_pos + x_test_neg\n","y_train = [True] * len(x_train_pos) + [False] * len(x_train_neg)\n","y_test = [True] * len(x_test_pos) + [False] * len(x_test_neg)\n","\n","# Embaralhamos o treino para depois fazermos a divisão treino/valid.\n","c = list(zip(x_train, y_train))\n","random.shuffle(c)\n","x_train, y_train = zip(*c)\n","\n","x_valid = x_train[-max_valid:]\n","y_valid = y_train[-max_valid:]\n","x_train = x_train[:-max_valid]\n","y_train = y_train[:-max_valid]\n","\n","print(len(x_train), 'amostras de treino.')\n","print(len(x_valid), 'amostras de desenvolvimento.')\n","print(len(x_test), 'amostras de teste.')\n","\n","print('3 primeiras amostras treino:')\n","for x, y in zip(x_train[:3], y_train[:3]):\n","    print(y, x[:100])\n","\n","print('3 últimas amostras treino:')\n","for x, y in zip(x_train[-3:], y_train[-3:]):\n","    print(y, x[:100])\n","\n","print('3 primeiras amostras validação:')\n","for x, y in zip(x_valid[:3], y_test[:3]):\n","    print(y, x[:100])\n","\n","print('3 últimas amostras validação:')\n","for x, y in zip(x_valid[-3:], y_valid[-3:]):\n","    print(y, x[:100])"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["20000 amostras de treino.\n","5000 amostras de desenvolvimento.\n","25000 amostras de teste.\n","3 primeiras amostras treino:\n","True This film is definitely an odd love story. Though this film may not be much to shout about, Nicole K\n","True I loved the idea of this film from the moment I first saw a trailer for it. Einstein has always been\n","False Did anyone edit this film? Or was it only the DVD release that had huge thirty second gaps between s\n","3 últimas amostras treino:\n","True Peter M. Cohen has a winner satire on the mating game, twisted around and turned inside out. The cri\n","True This is an \"odysessy through time\" via computer animation, supposedly th work of over 300 artists. M\n","True Sam Fuller's excellent PICK UP ON SOUTH STREET is the pick of the bunch from a number of early 50's \n","3 primeiras amostras validação:\n","True Terrible!!! I don't want to be too negative but this film has an IQ of stupid monkey.What a disaster\n","True This film deals with the atrocity in Derry 30 years ago which is commonly known as Bloody Sunday.<br\n","True I wasn't sure when I heard about this coming out. I was thinking how dumb is Disney getting. I was w\n","3 últimas amostras validação:\n","False If you're after the real story of early Baroque painter Artemisia Gentileschi, you'll be disappointe\n","True This movie is the first time movie experience for several people in the cast. All of them are experi\n","False I really tried to like this movie but in the end it just didn't work for me. I have seen most of Kit\n"]}]},{"cell_type":"markdown","metadata":{"id":"udZlSWLjIYLD"},"source":["## Iniciando modelo"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":182,"referenced_widgets":["0862510d46b947f7bd7b22870845945f","f5725e0b1f9240f9ae8eb575b6d626d9","a752b61f3bfd4c2e8cc67422495450d6","928bfbbce862444aa43686510473848c","063018d6498742c59ca2a42b667bcb26","eaf2a286420f4fbdb18b4763fb7623ae","55b10bceb5d14d7b8b3db70204250e76","bfc3dda882354343ae1efefce8bbb1f8","636ff716645f4cafb4df015539d89ef2","5cf511c8c41542ffa06b6ba96fffefeb","2c64baa47f934e30b542b55157447a7e"]},"id":"tpSYR8wMIpsc","executionInfo":{"status":"ok","timestamp":1634170650332,"user_tz":180,"elapsed":5352,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"23c08ca2-8789-448a-fb97-f55af75d6070"},"source":["tokenizer = BertTokenizer.from_pretrained(parametros['pretrained_model_name'])\n","tokenizer(x_train[0])"],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0862510d46b947f7bd7b22870845945f","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d8222bb20596416580353e25d531bb24","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b6f01e50856e4490ad7e7c4b2c0a4521","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fd2bff348f6049318c64ddc4816baf88","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [101, 2023, 2143, 2003, 5791, 2019, 5976, 2293, 2466, 1012, 2295, 2023, 2143, 2089, 2025, 2022, 2172, 2000, 11245, 2055, 1010, 9851, 4845, 2386, 7883, 1996, 2143, 2006, 2014, 2219, 1996, 2717, 1997, 1996, 3459, 2071, 3243, 4089, 2022, 6404, 1010, 2295, 3841, 23331, 2515, 2079, 3243, 1037, 2204, 3105, 1997, 18889, 2166, 2007, 7171, 1997, 2358, 26311, 1004, 19610, 2884, 19610, 4523, 14565, 2237, 2803, 10775, 1996, 2995, 11305, 1997, 1996, 2181, 1012, 2054, 4627, 17680, 2075, 2066, 1037, 3180, 2792, 1997, 1996, 2759, 2329, 2694, 2186, 1000, 12251, 1000, 2574, 4332, 2046, 1037, 24842, 3723, 20067, 2131, 9497, 2895, 17312, 1012, 2498, 5621, 13432, 6433, 1999, 2023, 3722, 2235, 2143, 1998, 2947, 4515, 1011, 2039, 2004, 7199, 11519, 5353, 4024, 1012, 1037, 2204, 2028, 2000, 3422, 1010, 1998, 2065, 2017, 2066, 1996, 5394, 2198, 2024, 9479, 4228, 2242, 2017, 2089, 2424, 2242, 2000, 6709, 2007, 1999, 2010, 2839, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":154,"referenced_widgets":["d47f28abebf64f788d5a4e05928aabde","17a5c7f38b204ee1b30ef464b6edb4a2","acc5a1dca510440b8690543b1b3f0968","173f858160074df7a7e9a2dce9dfa310","6ec7c303c990450499325345b12d7c06","69f7333a329b49939120d6886f038396","a4133649790a41c497780d084b1eae55","ce71745a169b423994e59a4c6826822b","02e27ea14bfe4c528d6e527c4b21b0c7","dc573b1acb8e4559b5c3d06eb272399e","7842ab52297b4abe93922c283c90f8fe"]},"id":"sPLEPLjLIsVy","executionInfo":{"status":"ok","timestamp":1634170707605,"user_tz":180,"elapsed":13770,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"6e14f0ff-a1a9-4f77-b68a-9603486e39cf"},"source":["model = BertForSequenceClassification.from_pretrained(parametros['pretrained_model_name'])"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d47f28abebf64f788d5a4e05928aabde","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gpGFMkoYI1oW","executionInfo":{"status":"ok","timestamp":1634170735360,"user_tz":180,"elapsed":769,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"d9cf2bfb-ac4b-42c8-ca1e-341bd84bbed2"},"source":["tokens = tokenizer(x_train[0], padding=True, truncation=True, return_tensors=\"pt\")\n","pred = model(**tokens)\n","print(pred)"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["SequenceClassifierOutput(loss=None, logits=tensor([[-0.2909, -0.4138]], grad_fn=<AddmmBackward>), hidden_states=None, attentions=None)\n"]}]},{"cell_type":"markdown","metadata":{"id":"UNaHbMHuI6RV"},"source":["## Dataset e Dataloader"]},{"cell_type":"code","metadata":{"id":"n1slKAN6I5aN"},"source":["class DataSet():\n","  def __init__(self, x, y):\n","    self.x = x\n","    self.y = y\n","  \n","  def __len__(self):\n","    return len(self.x)\n","  \n","  def __getitem__(self, idx):\n","    return self.x[idx], int(self.y[idx])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZfhREPCRI-4P"},"source":["def dl_gen(x, y, tokenizer, batch_size, shuffle=False, max_length=200):\n","  \n","    def collate_fn(batch):\n","  \n","          x, y = zip(*batch)\n","          tokenized_x = tokenizer(x, padding='longest', truncation=True, max_length=max_length, return_tensors='pt')\n","\n","          return tokenized_x['input_ids'], torch.LongTensor(y), tokenized_x['attention_mask']\n","  \n","    ds = DataSet(x,y)\n","    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H6TKIl7jJDuD"},"source":["## Funções de Treino e Teste"]},{"cell_type":"code","metadata":{"id":"SqEH3HYZJCVz"},"source":["def train(model, train, valid, optimizer, batch_count, filename_save, n_epochs, params=None):\n","  \n","    best_valid_loss = 99999999999999999\n","    best_epoch = 0\n","    count = 0\n","    train_losses, valid_losses = [], []\n","\n","    optimizer.zero_grad()\n","  \n","    for i in range(n_epochs):\n","\n","        accumulated_loss = 0\n","        model.train()\n","\n","        ######################## TREINO\n","\n","        for x_train, y_train, attention_mask in train:\n","\n","            # Cast in device (GPU or CPU)\n","            x_train = x_train.to(device)\n","            y_train = y_train.to(device)\n","            attention_mask = attention_mask.to(device)\n","\n","            # Forward\n","            outputs = model(input_ids=x_train, attention_mask=attention_mask, labels=y_train)\n","            batch_loss = outputs.loss\n","\n","\n","            # Backward\n","            batch_loss.backward()            \n","            if count == batch_count-1:\n","\n","                count = -1\n","                optimizer.step()\n","                optimizer.zero_grad()\n","      \n","            count += 1\n","            accumulated_loss += batch_loss.item()\n","\n","        train_loss = accumulated_loss / len(train.dataset)\n","        train_losses.append(train_loss)\n","\n","        ######################## VALIDAÇÃO\n","        accumulated_loss = 0\n","        accumulated_accuracy = 0\n","        model.eval()\n","        with torch.no_grad():\n","            for x_valid, y_valid, attention_mask in valid:\n","\n","                # Cast in device (GPU or CPU)\n","                x_valid = x_valid.to(device)\n","                y_valid = y_valid.to(device)\n","                attention_mask = attention_mask.to(device)\n","\n","                # Forward\n","                outputs = model(input_ids=x_valid, attention_mask=attention_mask, labels=y_valid)\n","\n","\n","                batch_loss = outputs.loss\n","                preds = outputs.logits.argmax(dim=1)\n","                batch_accuracy = (preds == y_valid).sum()\n","                accumulated_loss += batch_loss\n","                accumulated_accuracy += batch_accuracy\n","\n","        valid_loss = accumulated_loss / len(valid.dataset)\n","        valid_losses.append(valid_loss)\n","        valid_accuracy = accumulated_accuracy / len(valid.dataset)\n","    \n","        if valid_loss < best_valid_loss:\n","            model.save_pretrained(filename_save)\n","            best_valid_loss = valid_loss\n","            best_epoch = i\n","\n","            if i < 9:\n","                    print(f'Epoch = 0{i+1:d}/{n_epochs:d} | Train Loss = {train_loss:.6f} | Valid Loss = {valid_loss:.6f} | Valid Acc = {valid_accuracy*100:.1f}% | BEST MODEL')\n","            else:\n","                    print(f'Epoch = {i+1:d}/{n_epochs:d} | Train Loss = {train_loss:.6f} | Valid Loss = {valid_loss:.6f} | Valid Acc = {valid_accuracy*100:.1f}% | BEST MODEL')\n","\n","        else:\n","\n","            if i < 9:\n","                print(f'Epoch = 0{i+1:d}/{n_epochs:d} | Train Loss = {train_loss:.6f} | Valid Loss = {valid_loss:.6f} | Valid Acc = {valid_accuracy*100:.1f}%')\n","            else:\n","                print(f'Epoch = {i+1:d}/{n_epochs:d} | Train Loss = {train_loss:.6f} | Valid Loss = {valid_loss:.6f} | Valid Acc = {valid_accuracy*100:.1f}%')\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uj78VXwiJUu5"},"source":["def test(model, test):\n","    accumulated_accuracy = 0\n","    model.eval()\n","    with torch.no_grad():\n","        for x_test, y_test, attention_mask in test:\n","\n","            # Cast in device (CPU or GPU)\n","            x_test = x_test.to(device)\n","            y_test = y_test.to(device)\n","            attention_mask = attention_mask.to(device)\n","\n","            # Forward\n","            outputs = model(input_ids=x_test, attention_mask=attention_mask, labels=y_test)\n","            preds = outputs.logits.argmax(dim=1)\n","\n","            batch_accuracy = (preds == y_test_).sum()\n","            accumulated_accuracy += batch_accuracy\n","\n","    test_accuracy = accumulated_accuracy / len(test.dataset)\n","\n","    print(f'Accuracy = {test_accuracy * 100:.3f}%')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FkrMGX9OKhOU"},"source":["## Experimentos"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RybkmZVGK7E5","executionInfo":{"status":"ok","timestamp":1634151969963,"user_tz":180,"elapsed":18865,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"03f4a629-f81e-4db7-b11c-eb41edbd7144"},"source":["tokenizer = BertTokenizer.from_pretrained(parametros['pretrained_model_name'])\n","\n","model = BertForSequenceClassification.from_pretrained(parametros['pretrained_model_name'])\n","model.to(device)\n","\n","optimizer = AdamW(model.parameters(), lr=parametros['lr'])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","metadata":{"id":"Dflk3chaK7nY"},"source":["dl_train = dl_gen(x_train, y_train, tokenizer, parametros['batch_size'], shuffle=True, max_length=parametros['max_length'])\n","dl_valid = dl_gen(x_valid, y_valid, tokenizer, parametros['batch_size'], max_length=parametros['max_length'])\n","dl_test  = dl_gen(x_test,  y_test,  tokenizer, parametros['batch_size'], max_length=parametros['max_length'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VwpSYoBQK-GK","executionInfo":{"status":"ok","timestamp":1634158472544,"user_tz":180,"elapsed":740389,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"b7f198fc-44c9-494b-b9ba-65c200959969"},"source":["_ = train(model, dl_train, dl_valid, optimizer, 4, \"bert-imdb\", n_epochs=parametros['n_epochs'])"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["best model\n","Epoch = 01/3 | Train Loss = 0.014012 | Valid Loss = 0.010397 | Valid Acc = 91.8% | BEST MODEL\n","Epoch = 02/3 | Train Loss = 0.006843 | Valid Loss = 0.012135 | Valid Acc = 92.0%\n","Epoch = 03/3 | Train Loss = 0.003512 | Valid Loss = 0.015506 | Valid Acc = 91.0%\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AAYc_7r2LAuq","executionInfo":{"status":"ok","timestamp":1634168948920,"user_tz":180,"elapsed":12,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"d49eb425-8770-43dd-cbf7-76e807776e85"},"source":["test(model, dl_test)"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy = 91.320%\n"]}]},{"cell_type":"code","metadata":{"id":"8OonHAHHltjb"},"source":[""],"execution_count":null,"outputs":[]}]}