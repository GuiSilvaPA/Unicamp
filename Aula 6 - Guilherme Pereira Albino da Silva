{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Aula 6 - Guilherme Pereira Albino da Silva","provenance":[{"file_id":"1iCUWoyLkNU1-UmsB8YLfLvr3xwI04vIQ","timestamp":1632250530072},{"file_id":"1wpv_r96bBhIHJ3g9q3so3p8sHJ1HDk7H","timestamp":1631553851617},{"file_id":"1YW4O0K7EfSsgUe1kaZR9NswLXKVwqCb-","timestamp":1631389187602},{"file_id":"1Y3rRUiQGW5CEcPRkx_sfZGAEjNwVsw-b","timestamp":1631184728325},{"file_id":"1ONeS-lZ3vVqThueoTvQRMnZ_rJJB1yOl","timestamp":1629906878859}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"833b92400a784c0e9ab305d1f55b446e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7c87f57cc8cf486891166a1c293488c2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_289d444cab9948c499eb186c4a1ed996","IPY_MODEL_fa3bc536b4344b919845252b6b5f9f09","IPY_MODEL_1c6bdaab2090483da8f911fe92a17212"]}},"7c87f57cc8cf486891166a1c293488c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"289d444cab9948c499eb186c4a1ed996":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f727a33483924993980602bc9ac5b090","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"EPOCH:   0%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_050f1a881e394deebc1041934b398072"}},"fa3bc536b4344b919845252b6b5f9f09":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7788c4c19c3742d2ad4cabe3be5985bc","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":5,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6b87afbc1354489896e0acb86b51d379"}},"1c6bdaab2090483da8f911fe92a17212":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_067ad38741cf415781cd4d43e17434c5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/5 [04:03&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0bb31cbc00a4446b911187269858e642"}},"f727a33483924993980602bc9ac5b090":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"050f1a881e394deebc1041934b398072":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7788c4c19c3742d2ad4cabe3be5985bc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6b87afbc1354489896e0acb86b51d379":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"067ad38741cf415781cd4d43e17434c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0bb31cbc00a4446b911187269858e642":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c3014a2c38dd48009cdc9341536badb3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_82dcd15425ee4e378bbaed4fd804cde5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7c741e342dd848ffa82931915655beee","IPY_MODEL_ce681aed44474b27adb066f6278d5d9e","IPY_MODEL_07c6fe455e624a62a6f14d7b2a976cfb"]}},"82dcd15425ee4e378bbaed4fd804cde5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7c741e342dd848ffa82931915655beee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b09c426012e7492988c4d8df736eb9a8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"[TRAIN] Loss: 66511.90625, Perp: 773.7047119140625:  65%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_39eaa58ae7844ed9b599155752976653"}},"ce681aed44474b27adb066f6278d5d9e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_640f4b64a4f7489aa118e82dbbce9f44","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":543,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":355,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b876783f0f314b808513df4bc64908c7"}},"07c6fe455e624a62a6f14d7b2a976cfb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5511ec91708448038e88385a4bcb6109","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 355/543 [04:03&lt;02:07,  1.48it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e5bea4224ca34a2ab030bab3d7e62a70"}},"b09c426012e7492988c4d8df736eb9a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"39eaa58ae7844ed9b599155752976653":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"640f4b64a4f7489aa118e82dbbce9f44":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b876783f0f314b808513df4bc64908c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5511ec91708448038e88385a4bcb6109":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e5bea4224ca34a2ab030bab3d7e62a70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"1OG5DT_dm6mk"},"source":["# Notebook de referência \n","\n","Nome: Guilherme Pereira Albino da Silva - RA: 182786"]},{"cell_type":"markdown","metadata":{"id":"ojyVOubollcH"},"source":["## Definindo os parametros"]},{"cell_type":"code","metadata":{"id":"F-YHxi_AllQZ","executionInfo":{"status":"ok","timestamp":1632251328132,"user_tz":180,"elapsed":8,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}}},"source":["params = {\n","    'vocabulary_size': 10000\n","}"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uhpAkifICdJo"},"source":["# Fixando a seed"]},{"cell_type":"code","metadata":{"id":"1ozXD-xYCcrT","executionInfo":{"status":"ok","timestamp":1632251332109,"user_tz":180,"elapsed":3983,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}}},"source":["import os\n","import random\n","\n","import random\n","import torch\n","import numpy as np\n","\n","import collections\n","import re\n","\n","from typing import List\n","\n","import torch.nn.functional as F\n","\n","from torch.utils.data import DataLoader"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wHeZ9nAOEB0U","executionInfo":{"status":"ok","timestamp":1632251332111,"user_tz":180,"elapsed":21,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"f5961cfc-43b5-462d-a5a6-57f7d0bf6056"},"source":["random.seed(123)\n","np.random.seed(123)\n","torch.manual_seed(123)"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f584bb5cd30>"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"CXFdJz2KVeQw"},"source":["## Preparando Dados"]},{"cell_type":"markdown","metadata":{"id":"gHMi_Kq65fPM"},"source":["Primeiro, fazemos download do dataset:"]},{"cell_type":"code","metadata":{"id":"2wbnfzst5O3k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632251364792,"user_tz":180,"elapsed":32691,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"2b1f2b8f-ef7b-4e67-a95e-771a971bec23"},"source":["!wget -nc http://files.fast.ai/data/aclImdb.tgz \n","!tar -xzf aclImdb.tgz"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-09-21 19:08:52--  http://files.fast.ai/data/aclImdb.tgz\n","Resolving files.fast.ai (files.fast.ai)... 172.67.69.159, 104.26.3.19, 104.26.2.19, ...\n","Connecting to files.fast.ai (files.fast.ai)|172.67.69.159|:80... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://files.fast.ai/data/aclImdb.tgz [following]\n","--2021-09-21 19:08:53--  https://files.fast.ai/data/aclImdb.tgz\n","Connecting to files.fast.ai (files.fast.ai)|172.67.69.159|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 145982645 (139M) [application/x-gtar-compressed]\n","Saving to: ‘aclImdb.tgz’\n","\n","aclImdb.tgz         100%[===================>] 139.22M  9.45MB/s    in 16s     \n","\n","2021-09-21 19:09:09 (8.83 MB/s) - ‘aclImdb.tgz’ saved [145982645/145982645]\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"0Giyi5Rv_NIm"},"source":["## Carregando o dataset\n","\n","Criaremos uma divisão de treino (24k exemplos) e validação (1k exemplos) artificialmente.\n","\n","Nota: Evitar de olhar ao máximo o dataset de teste para não ficar enviseado no que será testado. Em aplicações reais, o dataset de teste só estará disponível no futuro, ou seja, é quando o usuário começa a testar o seu produto.\n","\n","Neste exercicio, iremos usar apenas 1000 exemplos de validação e 1000 de teste pois precisamos executar uma inferencia do modelo para cada _palavra_ do dataset.\n","\n","Como o aprendizado é não supervisionado, não iremos utilizar os rótulos."]},{"cell_type":"code","metadata":{"id":"0HIN_xLI_TuT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632251367300,"user_tz":180,"elapsed":2515,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"919cdfbf-5c47-4217-8c0d-06100ea86655"},"source":["import os\n","import random\n","\n","\n","max_valid = 1000\n","max_test = 1000\n","\n","\n","def load_texts(folder):\n","    texts = []\n","    for path in os.listdir(folder):\n","        with open(os.path.join(folder, path)) as f:\n","            texts.append(f.read())\n","    return texts\n","\n","x_train_pos = load_texts('aclImdb/train/pos')\n","x_train_neg = load_texts('aclImdb/train/neg')\n","x_test_pos = load_texts('aclImdb/test/pos')\n","x_test_neg = load_texts('aclImdb/test/neg')\n","\n","x_train = x_train_pos + x_train_neg\n","x_test = x_test_pos + x_test_neg\n","y_train = [True] * len(x_train_pos) + [False] * len(x_train_neg)\n","y_test = [True] * len(x_test_pos) + [False] * len(x_test_neg)\n","\n","# Embaralhamos o treino para depois fazermos a divisão treino/valid.\n","c = list(zip(x_train, y_train))\n","random.shuffle(c)\n","x_train, y_train = zip(*c)\n","\n","x_valid = x_train[-max_valid:]\n","y_valid = y_train[-max_valid:]\n","x_train = x_train[:-max_valid]\n","y_train = y_train[:-max_valid]\n","\n","# Embaralhamos o teste para diminuir a chance de algum viés nos 1000 exemplos amostrados.\n","c = list(zip(x_test, x_test))\n","random.shuffle(c)\n","x_test, x_test = zip(*c)\n","x_test = x_test[:max_test]\n","y_test = y_test[:max_test]\n","\n","print(len(x_train), 'amostras de treino.')\n","print(len(x_valid), 'amostras de desenvolvimento.')\n","print(len(x_test), 'amostras de teste.')\n","\n","print('3 primeiras amostras treino:')\n","for x, y in zip(x_train[:3], y_train[:3]):\n","    print(y, x[:100])\n","\n","print('3 últimas amostras treino:')\n","for x, y in zip(x_train[-3:], y_train[-3:]):\n","    print(y, x[:100])\n","\n","print('3 primeiras amostras validação:')\n","for x, y in zip(x_valid[:3], y_test[:3]):\n","    print(y, x[:100])\n","\n","print('3 últimas amostras validação:')\n","for x, y in zip(x_valid[-3:], y_valid[-3:]):\n","    print(y, x[:100])"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["24000 amostras de treino.\n","1000 amostras de desenvolvimento.\n","1000 amostras de teste.\n","3 primeiras amostras treino:\n","False I wholeheartedly disagree with the other viewers of this wretched film. The only reason why I didn't\n","False This film is really terrible. terrible as in it is a waste of 84 minutes of your life. Special effec\n","True I realize that alot of people hate this movie, but i must admit that it is one of my favorites. I ha\n","3 últimas amostras treino:\n","False Yet another forgettable Warners foreign intrigue \"thriller,\" this is rendered even less enjoyable by\n","False Cliché-ridden story of an impending divorce - or is it? - through the eyes of a 6 year-old child. Co\n","False Okay, so the previews to this film only tells you that a rebellious young girl goes to live with her\n","3 primeiras amostras validação:\n","True I do agree that though this story by Melville just might be unfilmable, this isn't even a credible t\n","True Very Slight Spoiler<br /><br /> This movie (despite being only on TV) is absolutely excellent. I did\n","True Hot Millions is a great movie in every way. A fun, offbeat story with wonderful performances by four\n","3 últimas amostras validação:\n","True I grew up with this as my all-time favorite film. The special effects are incredible for the era, an\n","True <br /><br />\"Burning Paradise\" is a combination of neo-Shaw Brothers action and Ringo Lam's urban cy\n","True This film is, quite simply, brilliant. The cinematography is good, the acting superb and the story a\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aiLnZh8fKXvm","executionInfo":{"status":"ok","timestamp":1632251367301,"user_tz":180,"elapsed":17,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"13485c0d-516d-4940-ed55-1fce6791da3a"},"source":["print(f'Numero de palavras treino: {sum([len(item.split()) for item in x_train])}')\n","print(f'Numero de palavras validação: {sum([len(item.split()) for item in x_valid])}')\n","print(f'Numero de palavras teste: {sum([len(item.split()) for item in x_test])}')"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Numero de palavras treino: 5611955\n","Numero de palavras validação: 232725\n","Numero de palavras teste: 226558\n"]}]},{"cell_type":"markdown","metadata":{"id":"XLlaPgP0Z_D4"},"source":["# Definindo o vocabulário"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YIpp1C_qZ-QX","executionInfo":{"status":"ok","timestamp":1632251371189,"user_tz":180,"elapsed":3395,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"114f2c31-eead-4b22-fa2e-a261d898593d"},"source":["import collections\n","import re\n","\n","\n","def tokenize(text):\n","    return [token.lower() for token in re.compile('\\w+').findall(text)]\n","\n","\n","vocabulary = collections.Counter([token for text in x_train for token in tokenize(text)]).most_common(params['vocabulary_size'])\n","vocabulary = list(dict(vocabulary).keys())\n","print('top 20 tokens do vocabulário:')\n","print('\\n'.join(vocabulary[:20]))\n","\n","vocabulary = {token: i for i, token in enumerate(vocabulary)}"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["top 20 tokens do vocabulário:\n","the\n","and\n","a\n","of\n","to\n","is\n","br\n","it\n","in\n","i\n","this\n","that\n","s\n","was\n","as\n","for\n","with\n","movie\n","but\n","film\n"]}]},{"cell_type":"code","metadata":{"id":"YnS0FcaluCgW","executionInfo":{"status":"ok","timestamp":1632251371191,"user_tz":180,"elapsed":12,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}}},"source":["from typing import List\n","\n","class Tokenizer:\n","    def __init__(self, vocabulary):\n","        self.vocabulary = vocabulary\n","\n","    def vocab_size(self) -> int:\n","        return len(self.vocabulary) \n","\n","    def encode(self, text) -> List[int]:\n","        # this will discard unknown tokens\n","        return [\n","            self.vocabulary[token] \n","            for token in tokenize(text) \n","            if token in self.vocabulary\n","        ]\n","\n","# unit test\n","def test_tokenizer():\n","    t = Tokenizer({'word1': 0, 'word2': 1, 'word3': 2})\n","    assert t.vocab_size() == 3\n","\n","    text = 'word1   word2 Word3    word4'\n","    assert t.encode(text) == [0,1,2]\n","\n","test_tokenizer()"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8LYuip6pwabM","executionInfo":{"status":"ok","timestamp":1632251374555,"user_tz":180,"elapsed":3372,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"e886c3b2-c72b-41ce-e945-5e42db9a4dfb"},"source":["import torch\n","\n","from torch.utils.data import Dataset\n","from bisect import bisect\n","\n","class CbowDataset(Dataset):\n","    def __init__(self, corpus, tokenizer: Tokenizer, padding: int = 1):\n","        super().__init__()\n","\n","        markers = []\n","        corpus_ids = []\n","        \n","        for text in corpus:\n","            ids = tokenizer.encode(text)\n","            markers.append(len(ids) - 2 * padding)\n","            corpus_ids.append(ids)\n","\n","        self.markers = torch.LongTensor(markers).cumsum(dim=0).tolist()\n","        self.corpus_ids = corpus_ids\n","        self.padding = padding\n","\n","    def __len__(self):\n","        return self.markers[-1]\n","\n","    def __getitem__(self, idx: int):\n","        # finds which sentence this word belongs to\n","        sentence_idx = bisect(self.markers, idx)\n","        \n","        # corrects the idx offset\n","        if sentence_idx > 0:\n","            idx = idx - self.markers[sentence_idx - 1]\n","\n","        target_idx = idx + self.padding\n","        sentence = self.corpus_ids[sentence_idx]\n","\n","        target = sentence[target_idx]\n","        input = (\n","            sentence[idx : target_idx] + \n","            sentence[target_idx + 1 : target_idx + self.padding + 1]\n","        )\n","\n","        return (torch.LongTensor(input), target)\n","\n","\n","def test_cbow_dataset():\n","    t = Tokenizer(vocabulary)\n","    ds = CbowDataset(x_train, t, padding=2)\n","\n","    print(len(ds))\n","\n","    encoding = t.encode(x_train[1])\n","    print(encoding)\n","    print(len(encoding))\n","\n","    print(ds[0])\n","    print(ds[1])\n","    print(ds[126])\n","\n","test_cbow_dataset()"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["5421518\n","[10, 19, 5, 64, 394, 394, 14, 8, 7, 5, 2, 438, 3, 231, 3, 128, 109, 318, 302, 25, 36, 394, 0, 113, 286, 20, 1070, 6, 6, 91, 43, 2, 4466, 11, 1260, 2, 637, 9372, 14, 32, 25, 1401, 2, 658, 43, 524, 4347, 524, 4347, 5, 53, 32, 7854, 186, 7986, 18, 7, 503, 394, 359, 53, 2, 1990, 4466, 39, 3167, 0, 7986, 88, 20, 167, 145, 0, 4466, 5, 58, 436, 1, 7, 211, 58, 52, 1218, 53, 32, 25, 616, 243, 806, 0, 1587, 18, 0, 4466, 211, 1545, 1, 232, 5271, 3185, 7, 0, 2468, 25, 1198, 1, 0, 7187, 25, 42, 4, 2237, 8, 57, 6, 6, 2, 1140, 394, 19, 1578, 23, 290, 317]\n","124\n","(tensor([   9, 3446,    0,   81]), 16)\n","(tensor([3446,   16,   81,  770]), 0)\n","(tensor([   4,   48, 1826,   43]), 699)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MiSNXnktwht2","executionInfo":{"status":"ok","timestamp":1632251380409,"user_tz":180,"elapsed":5877,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"7f71dbd6-31d3-47cd-d3af-840a5e9457b2"},"source":["from torch.utils.data import DataLoader\n","\n","tokenizer = Tokenizer(vocabulary)\n","padding = 2\n","batch_size = 10000\n","\n","ds_train = CbowDataset(x_train, tokenizer, padding)\n","ds_valid = CbowDataset(x_valid, tokenizer, padding)\n","ds_test = CbowDataset(x_test, tokenizer, padding)\n","\n","dl_train = DataLoader(ds_train, shuffle=True, batch_size=batch_size, num_workers=2)\n","dl_valid = DataLoader(ds_valid, shuffle=True, batch_size=batch_size, num_workers=2)\n","dl_test = DataLoader(ds_test, shuffle=False, batch_size=batch_size, num_workers=2)\n","\n","def test_dataloaders():\n","    print('Number of train batches:', len(dl_train))\n","    print('Number of validation batches:', len(dl_valid))\n","    print('Number of test batches:', len(dl_test))\n","\n","    x, y = next(iter(dl_train))\n","\n","    print(x.shape)\n","    print(y.shape)\n","\n","test_dataloaders()"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of train batches: 543\n","Number of validation batches: 23\n","Number of test batches: 22\n","torch.Size([10000, 4])\n","torch.Size([10000])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XJ9MKYf5uWhC","executionInfo":{"status":"ok","timestamp":1632251380411,"user_tz":180,"elapsed":43,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"3bc1b6d2-3f54-4a82-b2d6-2beb3b9d6185"},"source":["def perplexity(cross_entropy, n):\n","    return 2 ** ((1/n) * (cross_entropy / torch.tensor(2.).log()))\n","\n","def test_perplexity():\n","    ce1 = F.cross_entropy(torch.FloatTensor([[0,1,0,0]]), torch.tensor([1]), reduction='sum')\n","    ce2 = F.cross_entropy(torch.FloatTensor([[0,0,0,1]]), torch.tensor([3]), reduction='sum')\n","\n","    print(perplexity(ce1, 1))\n","    print(perplexity(ce2, 1))\n","\n","test_perplexity() "],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(2.1036)\n","tensor(2.1036)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"60BYOLJguYQ_","executionInfo":{"status":"ok","timestamp":1632251419732,"user_tz":180,"elapsed":9291,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"bb0d31fe-b131-44e6-b7a5-12a60249a84d"},"source":["class Model(torch.nn.Module):\n","    def __init__(self, vocab_size: int, embedding_size: int):\n","        super().__init__()\n","\n","        self.dense = torch.nn.Sequential(\n","            torch.nn.ReLU(),\n","            torch.nn.Linear(embedding_size, 512),\n","            torch.nn.ReLU(),\n","            torch.nn.Linear(512, 1024),\n","            torch.nn.ReLU(),\n","            torch.nn.Linear(1024, 2048),\n","            torch.nn.ReLU(),\n","            torch.nn.Linear(2048, vocab_size)\n","        )\n","\n","        self.embedding = torch.nn.Embedding(vocab_size, embedding_size)\n","\n","    def forward(self, x):\n","        embs = self.embedding(x).sum(dim=1)\n","        return self.dense(embs)\n","\n","def test_model():\n","    m = Model(vocab_size=tokenizer.vocab_size(), embedding_size=300)\n","    m.eval()\n","\n","    with torch.no_grad():\n","        x, y = next(iter(dl_train))\n","        pred = m(x)\n","        print(pred.shape)\n","        print(F.cross_entropy(pred, y, reduction='sum'))\n","        print(perplexity(F.cross_entropy(pred, y, reduction='sum'), len(x)))\n","\n","test_model()"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([10000, 10000])\n","tensor(92243.9922)\n","tensor(10141.5801)\n"]}]},{"cell_type":"code","metadata":{"id":"VWg71X5CuZ3d","executionInfo":{"status":"ok","timestamp":1632251423467,"user_tz":180,"elapsed":796,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}}},"source":["from torch.optim import Adam\n","from torch.nn import CrossEntropyLoss\n","from tqdm.notebook import tqdm\n","\n","import matplotlib.pyplot as plt\n","\n","class Trainer:\n","    def __init__(self, n_epochs: int, model: Model, lr: float, best_model_filename: str = 'best_model.pt'):\n","        self.model = model\n","        self.optimizer = Adam(self.model.parameters(), lr=lr)\n","        self.n_epochs = n_epochs\n","        self.train_losses = []\n","        self.valid_losses = []\n","        self.train_perplexities = []\n","        self.valid_perplexities = []\n","        self.loss_fn = CrossEntropyLoss(reduction='sum')\n","        self.best_model_filename = best_model_filename\n","\n","        device_name = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n","        \n","        self.device = torch.device(device_name)\n","\n","    def train(self, dl_train: DataLoader, dl_valid: DataLoader):\n","        best_model_perplexity = None\n","        self.model.to(self.device)\n","\n","        print('Training starting...')\n","        epoch_iter = tqdm(range(self.n_epochs))\n","        epoch_iter.set_description('EPOCH')\n","\n","        for _ in epoch_iter:\n","            batch_train_loss = 0\n","            batch_train_perplexity = 0\n","\n","            self.model.train()\n","\n","            batch_iter = tqdm(dl_train)\n","\n","            for x_train, y_train in batch_iter:\n","                x_train = x_train.to(self.device)\n","                y_train = y_train.to(self.device)\n","\n","                pred = self.model(x_train)\n","                loss = self.loss_fn(pred, y_train)\n","\n","                self.optimizer.zero_grad()\n","                loss.backward()\n","                self.optimizer.step()\n","\n","                loss_item = loss.item()\n","                batch_perp = perplexity(loss_item, len(y_train))\n","\n","                batch_iter.set_description(f'[TRAIN] Loss: {loss_item}, Perp: {batch_perp}')\n","                batch_train_loss += loss_item\n","                batch_train_perplexity += batch_perp\n","\n","            self.train_perplexities.append(batch_train_perplexity / len(dl_train))\n","            self.train_losses.append(batch_train_loss / len(dl_train))\n","\n","            with torch.no_grad():\n","                batch_valid_loss = 0\n","                batch_perplexity = 0\n","\n","                self.model.eval()\n","\n","                valid_iter = tqdm(dl_valid)\n","                \n","                for x_valid, y_valid in valid_iter:\n","                    x_valid = x_valid.to(self.device)\n","                    y_valid = y_valid.to(self.device)\n","\n","                    pred = self.model(x_valid)\n","                    loss = self.loss_fn(pred, y_valid)\n","                    perp = perplexity(loss.item(), len(y_valid))\n","\n","                    batch_valid_loss += loss.item()\n","                    batch_perplexity += perp\n","\n","                    valid_iter.set_description(f'[VALID] Loss: {loss.item()}, Perp: {perp}')\n","\n","                self.valid_perplexities.append(batch_perplexity / len(dl_valid))\n","                self.valid_losses.append(batch_valid_loss / len(dl_valid))\n","\n","                if best_model_perplexity is None or batch_perplexity < best_model_perplexity:\n","                    torch.save(self.model.state_dict(), self.best_model_filename)\n","                    best_model_perplexity = batch_perplexity\n","\n","    def evaluate(self, dl_test):\n","        self.model.load_state_dict(torch.load(self.best_model_filename))\n","        self.model.eval()\n","        self.model.to(self.device)\n","\n","        final_loss = 0\n","        final_perplexity = 0\n","\n","        print('Evaluating the best model found...')\n","\n","        with torch.no_grad():\n","            for x_test, y_test in tqdm(dl_test):\n","                x_test = x_test.to(self.device)\n","                y_test = y_test.to(self.device)\n","\n","                pred = self.model(x_test)\n","                loss = self.loss_fn(pred, y_test)\n","                final_loss += loss.item()\n","                final_perplexity += perplexity(loss.item(), len(y_test))\n","\n","        return {\n","            'loss': final_loss / len(dl_test),\n","            'perplexity': final_perplexity / len(dl_test)\n","        }"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":455,"referenced_widgets":["833b92400a784c0e9ab305d1f55b446e","7c87f57cc8cf486891166a1c293488c2","289d444cab9948c499eb186c4a1ed996","fa3bc536b4344b919845252b6b5f9f09","1c6bdaab2090483da8f911fe92a17212","f727a33483924993980602bc9ac5b090","050f1a881e394deebc1041934b398072","7788c4c19c3742d2ad4cabe3be5985bc","6b87afbc1354489896e0acb86b51d379","067ad38741cf415781cd4d43e17434c5","0bb31cbc00a4446b911187269858e642","c3014a2c38dd48009cdc9341536badb3","82dcd15425ee4e378bbaed4fd804cde5","7c741e342dd848ffa82931915655beee","ce681aed44474b27adb066f6278d5d9e","07c6fe455e624a62a6f14d7b2a976cfb","b09c426012e7492988c4d8df736eb9a8","39eaa58ae7844ed9b599155752976653","640f4b64a4f7489aa118e82dbbce9f44","b876783f0f314b808513df4bc64908c7","5511ec91708448038e88385a4bcb6109","e5bea4224ca34a2ab030bab3d7e62a70"]},"id":"mlCg4JcEubwC","executionInfo":{"status":"error","timestamp":1632251971679,"user_tz":180,"elapsed":244363,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07971392613373651702"}},"outputId":"7f8713d8-ce35-4c74-ab1f-0be9ebe1e7af"},"source":["n_epochs = 5\n","embedding_dim = 300\n","lr = 0.1\n","vocab_size = tokenizer.vocab_size()\n","model=Model(embedding_size=embedding_dim, vocab_size=vocab_size)\n","batch_size = 64\n","\n","params = {\n","    'window_size': 2 * padding + 1,\n","    'n_epochs': n_epochs,\n","    'batch_size': batch_size,\n","    'embedding_dim': embedding_dim,\n","    'vocab_size': tokenizer.vocab_size()\n","}\n","\n","print(f'Params: {params}')\n","\n","trainer = Trainer(\n","    model=model,\n","    n_epochs=n_epochs,\n","    lr=lr\n",")\n","\n","trainer.train(dl_train, dl_valid)\n","print('Results (avg): ', trainer.evaluate(dl_test))"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Params: {'window_size': 5, 'n_epochs': 5, 'batch_size': 64, 'embedding_dim': 300, 'vocab_size': 10000}\n","Training starting...\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"833b92400a784c0e9ab305d1f55b446e","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/5 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c3014a2c38dd48009cdc9341536badb3","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/543 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-470aa5eebf2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Results (avg): '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-c5116856fe54>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dl_train, dl_valid)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}