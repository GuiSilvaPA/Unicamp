{"cells":[{"cell_type":"markdown","id":"b77b1131-fd61-4753-9993-581b75bbed40","metadata":{"id":"b77b1131-fd61-4753-9993-581b75bbed40"},"source":["# CNN Example\n","\n","https://www.youtube.com/watch?v=wnK3uWv_WkU&list=PLhhyoLH6IjfxeoooqP9rhU3HJIAVAJ3Vz&index=4"]},{"cell_type":"code","execution_count":null,"id":"fc47594c-a84c-4cce-8c40-5cf77a5974b0","metadata":{"id":"fc47594c-a84c-4cce-8c40-5cf77a5974b0"},"outputs":[],"source":["import torch\n","import torch.nn as nn                            # Neural Network Models\n","import torch.optim as optim                      # Optimization algorithms\n","import torch.nn.functional as F                  # Functions that don't have parameters\n","from torch.utils.data import DataLoader          # Easier dataset management\n","\n","import torchvision.datasets as datasets          # Standard datasets\n","import torchvision.transforms as transforms      # Transformations for dataset"]},{"cell_type":"markdown","id":"ce75fa44-41b5-4c04-a005-e68d2e7aee85","metadata":{"id":"ce75fa44-41b5-4c04-a005-e68d2e7aee85"},"source":["## CNN"]},{"cell_type":"code","execution_count":null,"id":"9cc6c79d-d756-4f48-843e-097d128977a4","metadata":{"id":"9cc6c79d-d756-4f48-843e-097d128977a4"},"outputs":[],"source":["class CNN(nn.Module):\n","    \n","    def __init__(self, in_channels=1, num_classes=10):\n","        \n","        super(CNN, self).__init__()\n","        \n","        # same convolution: output_size = input_size\n","        self.conv1  = nn.Conv2d(in_channels=in_channels, out_channels=8, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n","        self.pool   = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n","        self.conv2  = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n","        self.fc1    = nn.Linear(16*7*7, 20)\n","        self.fc2    = nn.Linear(20, num_classes)\n","        self.fci1   = nn.Linear(num_classes, 20)\n","        self.fci2   = nn.Linear(20, 16*7*7)\n","        self.convt1 = nn.ConvTranspose2d(16, 8, kernel_size=2, stride=2)\n","        self.convt2 = nn.ConvTranspose2d(8, 8, kernel_size=2, stride=2)\n","\n","\n","    def forward(self, x):\n","        \n","        x = F.relu(self.conv1(x))\n","        print(x.shape)\n","        x = self.pool(x)\n","        print(x.shape)\n","        x = F.relu(self.conv2(x))\n","        print(x.shape)\n","        x = self.pool(x)\n","\n","        print(x.shape)\n","        x = x.reshape(x.shape[0], -1)\n","        print(x.shape)        \n","        x = self.fc1(x)\n","        print(x.shape)\n","        x = self.fc2(x)\n","        print(x.shape)\n","        x = self.fci1(x)\n","        print(x.shape)\n","        x = self.fci2(x)\n","        print(x.shape)\n","        x = x.reshape(x.shape[0], 16, 7, 7)\n","        print(x.shape)\n","        x = self.convt1(x)\n","        print(x.shape)\n","        x = self.convt2(x)\n","        print(x.shape)\n","        \n","        return x"]},{"cell_type":"code","execution_count":null,"id":"a83ca83f-f2c0-4ac7-9aa8-395cc4f9a484","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a83ca83f-f2c0-4ac7-9aa8-395cc4f9a484","executionInfo":{"status":"ok","timestamp":1652140037599,"user_tz":180,"elapsed":421,"user":{"displayName":"Guilherme Pereira Albino da Silva","userId":"07971392613373651702"}},"outputId":"7db869b3-7795-475d-dc7a-80d457b13834"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 8, 28, 28])\n","torch.Size([64, 8, 14, 14])\n","torch.Size([64, 16, 14, 14])\n","torch.Size([64, 16, 7, 7])\n","torch.Size([64, 784])\n","torch.Size([64, 20])\n","torch.Size([64, 10])\n","torch.Size([64, 20])\n","torch.Size([64, 784])\n","torch.Size([64, 16, 7, 7])\n","torch.Size([64, 8, 14, 14])\n","torch.Size([64, 8, 28, 28])\n"]}],"source":["model = CNN()\n","x = torch.randn(64, 1, 28, 28)\n","y = model(x)"]},{"cell_type":"code","source":["x = torch.randn(64, 1, 28, 28)\n","s = x.shape[1:]\n","s[0] * s[1] * s[2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iKptYyhDSHn0","executionInfo":{"status":"ok","timestamp":1652141171823,"user_tz":180,"elapsed":7,"user":{"displayName":"Guilherme Pereira Albino da Silva","userId":"07971392613373651702"}},"outputId":"4585f8aa-2870-4d87-9c20-6888dba01003"},"id":"iKptYyhDSHn0","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["784"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["features = 512\n","model = EncoderFC(features)\n","x = torch.randn(64, features, 2, 45)\n","y = model(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mSpIfXJYWLwD","executionInfo":{"status":"ok","timestamp":1652144466471,"user_tz":180,"elapsed":1355,"user":{"displayName":"Guilherme Pereira Albino da Silva","userId":"07971392613373651702"}},"outputId":"17066b0a-88f0-42b8-8c4b-dbc5122a51e6"},"id":"mSpIfXJYWLwD","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 46080])\n","torch.Size([64, 1024])\n","torch.Size([64, 512])\n","torch.Size([64, 1024])\n","torch.Size([64, 46080])\n","torch.Size([64, 512, 2, 45])\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","from torchsummary import summary\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from os import listdir\n","from os.path import isfile, join\n","\n","from tqdm import tqdm\n","\n","import random\n","\n","import torch.optim as optim\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","import pandas as pd\n","\n","from os import listdir\n","from os.path import isfile, join\n","\n","from tqdm import tqdm\n","\n","import random\n","\n","import torch\n","from torch import nn, sigmoid\n","from torch.nn.modules.upsampling import Upsample\n","from torch.nn.functional import interpolate\n","from torch.autograd import Variable\n","from torch.nn import MaxPool2d\n","from torch.nn.modules.conv import Conv2d\n","from torch.nn.modules.activation import Sigmoid, ReLU\n","\n","from torchsummary import summary\n","\n","from sklearn.neighbors import NearestNeighbors\n","from sklearn.cluster import KMeans\n","from sklearn.cluster import SpectralClustering\n","from sklearn.preprocessing import normalize\n","from scipy.spatial.distance import cosine as cosine_distance\n","\n","from torchsummary import summary\n","import torchvision.transforms.functional as TF"],"metadata":{"id":"NLM_fEJQYs0B"},"id":"NLM_fEJQYs0B","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define model of double convolution\n","\n","class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(DoubleConv, self).__init__()\n","        \n","        self.conv = nn.Sequential(\n","        \n","            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            \n","            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","        \n","        )\n","        \n","    def forward(self, x):\n","        return self.conv(x)"],"metadata":{"id":"JzGUX2-ZYswp"},"id":"JzGUX2-ZYswp","execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Encoder(nn.Module):\n","    def __init__(self, in_channels, features=[64, 128, 256, 512]):\n","        super(Encoder, self).__init__()\n","        \n","        self.downs = nn.ModuleList()\n","        self.pool  = nn.MaxPool2d(kernel_size=2, stride=2)\n","        \n","        for feature in features:\n","            self.downs.append(DoubleConv(in_channels, feature))\n","            in_channels = feature\n","            \n","        self.skip_connections = []\n","        \n","    def forward(self, x):\n","        \n","        for down in self.downs:\n","            x = down(x)\n","            self.skip_connections.append(x)\n","            x = self.pool(x)\n","        \n","        return x"],"metadata":{"id":"IgrHWxrLYsi-"},"id":"IgrHWxrLYsi-","execution_count":null,"outputs":[]},{"cell_type":"code","source":["class UNet(nn.Module):\n","    def __init__(self, in_channels, out_channels, features):\n","        super(UNet, self).__init__()\n","        \n","        self.encoder = Encoder(in_channels, features)\n","        self.ups     = nn.ModuleList()\n","\n","        self.fce     = EncoderFC(512)\n","        self.fcd     = DecoderFC(512)\n","        \n","        for feature in reversed(features):\n","            self.ups.append(nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2))\n","            self.ups.append(DoubleConv(feature*2, feature))\n","            \n","        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n","        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n","        \n","        self.decoder_skip_connections = []\n","        \n","    def forward(self, x):\n","        \n","        x = self.encoder(x)\n","\n","        s = x.shape[0]\n","        x = self.fce(x, s)\n","        x = self.fcd(x, s)\n","        \n","        x = self.bottleneck(x)\n","        \n","        self.decoder_skip_connections.append(x)\n","\n","        \n","        self.encoder_skip_connections = self.encoder.skip_connections[::-1]\n","        \n","        for i in range(0, len(self.ups), 2):\n","            \n","            x = self.ups[i](x)\n","            \n","            self.decoder_skip_connections.append(x)\n","        \n","            skip_connection = self.encoder_skip_connections[i//2]\n","            if x.shape != skip_connection.shape:\n","                x = TF.resize(x, size=skip_connection.shape[2:])\n","                \n","            concat_skip = torch.cat((skip_connection, x), dim=1)\n","            \n","            x = self.ups[i+1](concat_skip)\n","        \n","        return self.final_conv(x)"],"metadata":{"id":"woJaGS92Ysf0"},"id":"woJaGS92Ysf0","execution_count":null,"outputs":[]},{"cell_type":"code","source":["class EncoderFC(nn.Module):\n","    def __init__(self, features=512):\n","        super(EncoderFC, self).__init__()\n","\n","        self.features = features\n","\n","        self.fci1  = nn.Sequential(nn.Linear(features*1*22, features*2),\n","                                   nn.ReLU(),\n","                                   nn.Linear(features*2, features),\n","                                   nn.ReLU())\n","        \n","        \n","        \n","    def forward(self, x, s):\n","\n","        print(x.shape)\n","        x = x.reshape(s, -1)\n","        print(x.shape)\n","\n","        x = self.fci1(x)\n","        print(x.shape)\n","        \n","        return x"],"metadata":{"id":"bOCkBzZaRkdy"},"id":"bOCkBzZaRkdy","execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DecoderFC(nn.Module):\n","    def __init__(self, features=512):\n","        super(DecoderFC, self).__init__()\n","\n","        self.features = features\n","        self.fci2 = nn.Sequential(nn.Linear(features, features*2),\n","                                  nn.ReLU(),\n","                                  nn.Linear(features*2, features*1*22),\n","                                  nn.ReLU())\n","        \n","        \n","        \n","    def forward(self, x, s):\n","\n","        x = self.fci2(x)\n","        print(x.shape)\n","\n","        x = x.reshape(s, self.features, 1, 22)\n","        print(x.shape)\n","        \n","        return x"],"metadata":{"id":"EVZyyw0rk8gQ"},"id":"EVZyyw0rk8gQ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["x     = torch.randn((8, 3, 23, 360))\n","model = UNet(3, 3, [64, 128, 256, 512])\n","preds = model(x)\n","\n","print(x.shape)\n","print(preds.shape)\n","\n","print(f'\\nConnections:\\n')\n","for i in reversed(model.encoder_skip_connections):\n","    print(i.shape)\n","\n","print(f'')    \n","\n","for i, m in enumerate(model.decoder_skip_connections):\n","    print(m.shape)\n","    if i == 0:\n","        print(f'')\n","        \n","# summary(model, input_size=(1, 360, 68))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"73lLRTB-Ysc_","executionInfo":{"status":"ok","timestamp":1652147462033,"user_tz":180,"elapsed":2308,"user":{"displayName":"Guilherme Pereira Albino da Silva","userId":"07971392613373651702"}},"outputId":"2b6f3aa2-92dd-4798-e319-da578eec911f"},"id":"73lLRTB-Ysc_","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([8, 512, 1, 22])\n","torch.Size([8, 11264])\n","torch.Size([8, 512])\n","torch.Size([8, 11264])\n","torch.Size([8, 512, 1, 22])\n","torch.Size([8, 3, 23, 360])\n","torch.Size([8, 3, 23, 360])\n","\n","Connections:\n","\n","torch.Size([8, 64, 23, 360])\n","torch.Size([8, 128, 11, 180])\n","torch.Size([8, 256, 5, 90])\n","torch.Size([8, 512, 2, 45])\n","\n","torch.Size([8, 1024, 1, 22])\n","\n","torch.Size([8, 512, 2, 44])\n","torch.Size([8, 256, 4, 90])\n","torch.Size([8, 128, 10, 180])\n","torch.Size([8, 64, 22, 360])\n"]}]},{"cell_type":"code","source":["output = model.encoder(x)\n","output = model.fce(output, output.shape[0])\n","output.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5qL3SNXAYsZ5","executionInfo":{"status":"ok","timestamp":1652147478680,"user_tz":180,"elapsed":669,"user":{"displayName":"Guilherme Pereira Albino da Silva","userId":"07971392613373651702"}},"outputId":"4cca25f3-8d12-47cd-9804-e84b3bb22490"},"id":"5qL3SNXAYsZ5","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([8, 512, 1, 22])\n","torch.Size([8, 11264])\n","torch.Size([8, 512])\n"]},{"output_type":"execute_result","data":{"text/plain":["torch.Size([8, 512])"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["output = model.fc(x)\n","output.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"9xVQSBMCYsW1","executionInfo":{"status":"error","timestamp":1652144982788,"user_tz":180,"elapsed":428,"user":{"displayName":"Guilherme Pereira Albino da Silva","userId":"07971392613373651702"}},"outputId":"1bfb921a-332a-41fb-95aa-67738e919741"},"id":"9xVQSBMCYsW1","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 3, 23, 360])\n","torch.Size([64, 24840])\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-79-38da69b95c2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-76-5f184bad4f6b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfci1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfci2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x24840 and 11264x1024)"]}]},{"cell_type":"markdown","id":"6262d120-f7d0-45c2-801a-2da77a92562c","metadata":{"id":"6262d120-f7d0-45c2-801a-2da77a92562c"},"source":["## Set Device"]},{"cell_type":"code","execution_count":null,"id":"a61f84a1-4875-4b25-9405-bc5678463796","metadata":{"id":"a61f84a1-4875-4b25-9405-bc5678463796","outputId":"f5f79200-0e7b-4679-d0df-b67f562cf534"},"outputs":[{"data":{"text/plain":["device(type='cpu')"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"markdown","id":"d0d57767-d4e4-4faf-8e5c-75340833336e","metadata":{"id":"d0d57767-d4e4-4faf-8e5c-75340833336e"},"source":["## Hyperparameters"]},{"cell_type":"code","execution_count":null,"id":"afa3e77b-5734-40c0-b446-d8144f3899fc","metadata":{"id":"afa3e77b-5734-40c0-b446-d8144f3899fc"},"outputs":[],"source":["in_channels = 1\n","num_classes = 10\n","lr          = 0.001\n","batch_size  = 64\n","n_epochs    = 1"]},{"cell_type":"markdown","id":"1593c675-354e-48e6-b253-ba52a0985575","metadata":{"id":"1593c675-354e-48e6-b253-ba52a0985575"},"source":["## Load Data"]},{"cell_type":"code","execution_count":null,"id":"0f08719a-27fe-4750-bb11-85abf1c488a7","metadata":{"id":"0f08719a-27fe-4750-bb11-85abf1c488a7","outputId":"a1351126-39dc-4805-e00f-570eb3ebfbcf"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Scarlet\\anaconda3\\envs\\ENV\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n","  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"]}],"source":["train_dataset = datasets.MNIST(root='dataset/',\n","                               train=True,\n","                               transform=transforms.ToTensor(),\n","                               download=True)\n","\n","test_dataset  = datasets.MNIST(root='dataset/',\n","                               train=False,\n","                               transform=transforms.ToTensor(),\n","                               download=True)"]},{"cell_type":"code","execution_count":null,"id":"18a9b1a6-0c8c-48fd-a4aa-2ddede8a9238","metadata":{"id":"18a9b1a6-0c8c-48fd-a4aa-2ddede8a9238"},"outputs":[],"source":["train_loader = DataLoader(train_dataset, \n","                          batch_size=batch_size,\n","                          shuffle=True)\n","test_loader  = DataLoader(test_dataset, \n","                          batch_size=batch_size,\n","                          shuffle=True)"]},{"cell_type":"markdown","id":"c4c65ff5-a483-4a57-98d1-f8c32cb3e6a5","metadata":{"id":"c4c65ff5-a483-4a57-98d1-f8c32cb3e6a5"},"source":["## Initialize the Network"]},{"cell_type":"code","execution_count":null,"id":"eca9ead3-7e8f-436f-a7b6-a97ff1da0aa3","metadata":{"id":"eca9ead3-7e8f-436f-a7b6-a97ff1da0aa3"},"outputs":[],"source":["model = CNN(in_channels=in_channels,\n","            num_classes=num_classes)\n","\n","model = model.to(device)"]},{"cell_type":"markdown","id":"392263bf-4aa5-403d-9f76-0b9016c6e7f9","metadata":{"id":"392263bf-4aa5-403d-9f76-0b9016c6e7f9"},"source":["## Loss and Optimizer"]},{"cell_type":"code","execution_count":null,"id":"7b6df124-c255-4005-97b0-e8b08fff0ca9","metadata":{"id":"7b6df124-c255-4005-97b0-e8b08fff0ca9"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=lr)"]},{"cell_type":"markdown","id":"526b8e1f-b2a7-4703-a578-5c3062685616","metadata":{"id":"526b8e1f-b2a7-4703-a578-5c3062685616"},"source":["## Train the Network"]},{"cell_type":"code","execution_count":null,"id":"6f046f20-dfb0-4e3d-ae7e-2cf80573ec0d","metadata":{"id":"6f046f20-dfb0-4e3d-ae7e-2cf80573ec0d"},"outputs":[],"source":["for epoch in range(n_epochs):\n","    \n","    for batch_idx, (data, targets) in enumerate(train_loader):\n","        \n","        data    = data.to(device=device)\n","        targets = targets.to(device=device)\n","        \n","        # Forward\n","        targets_pred = model(data)\n","        loss         = criterion(targets_pred, targets)\n","        \n","        # Backward\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()"]},{"cell_type":"markdown","id":"75196b09-aa06-40a1-8161-ca676e1566a5","metadata":{"id":"75196b09-aa06-40a1-8161-ca676e1566a5"},"source":["## Test Accuracy"]},{"cell_type":"code","execution_count":null,"id":"491eee8e-bf09-4c9f-8cbb-1b9e4b741743","metadata":{"id":"491eee8e-bf09-4c9f-8cbb-1b9e4b741743"},"outputs":[],"source":["def check_accuracy(loader, model):\n","    \n","    num_corrects = 0\n","    num_samples  = 0\n","    \n","    if loader.dataset.train:\n","        print('Checking accuracy on training data: \\n')\n","    else:\n","        print('Checking accuracy on test data: \\n')\n","        \n","    model.eval()\n","    \n","    with torch.no_grad():\n","        \n","        for x, y in loader:\n","            \n","            x = x.to(device=device)\n","            y = y.to(device=device)\n","            \n","            score = model(x)            \n","            _, pred = score.max(dim=1)\n","    \n","    \n","            num_corrects += (pred == y).sum()\n","            num_samples  += pred.size(0)\n","            \n","        acc = (num_corrects*100)/num_samples\n","        \n","        print(f'Corrects: {num_corrects} \\nSamples: {num_samples} \\nAccuracy: {acc:0.4f}')"]},{"cell_type":"code","execution_count":null,"id":"5dbe57a8-e52f-410b-982a-b0246535af37","metadata":{"id":"5dbe57a8-e52f-410b-982a-b0246535af37","outputId":"9d63cf8a-59e4-4d65-ea22-d9abba123b2c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Checking accuracy on training data: \n","\n","Corrects: 57708 \n","Samples: 60000 \n","Accuracy: 96.1800\n"]}],"source":["check_accuracy(train_loader, model)"]},{"cell_type":"code","execution_count":null,"id":"927f06c3-9de7-457e-9c69-a0bd68089e4d","metadata":{"id":"927f06c3-9de7-457e-9c69-a0bd68089e4d","outputId":"3ed58ab8-bd4f-4c84-84a3-a5a868e5a645"},"outputs":[{"name":"stdout","output_type":"stream","text":["Checking accuracy on test data: \n","\n","Corrects: 9658 \n","Samples: 10000 \n","Accuracy: 96.5800\n"]}],"source":["check_accuracy(test_loader, model)"]},{"cell_type":"code","execution_count":1,"id":"3b964476-f9f1-42c5-8dbd-fd86b1d0dc6a","metadata":{"id":"3b964476-f9f1-42c5-8dbd-fd86b1d0dc6a","executionInfo":{"status":"ok","timestamp":1652183329469,"user_tz":180,"elapsed":13,"user":{"displayName":"Guilherme Pereira Albino da Silva","userId":"07971392613373651702"}}},"outputs":[],"source":["import numpy as np\n","from google.colab import drive"]},{"cell_type":"code","source":["drive.mount(\"/content/drive\")"],"metadata":{"id":"UK2HE9JLzPj0"},"id":"UK2HE9JLzPj0","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.11"},"colab":{"name":"3. CNN.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}