{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Aula 1 - Guilherme Pereira Albino da Silva","provenance":[{"file_id":"1nfWezvbyEvskMWvjO5m24fQPcHEhQ7m6","timestamp":1629281111012},{"file_id":"1r_8o7veIejMQYaBBVyiloHYjvj3D1U06","timestamp":1626725509609},{"file_id":"10dkZp5KN4zETvJ6kabq2pA1UIZ4U7MEg","timestamp":1626722779644},{"file_id":"19LKlqlAGHoAH6nbJMJYjktKfJ3N8TNWJ","timestamp":1597920482189},{"file_id":"https://github.com/robertoalotufo/rnap/blob/master/PyTorch/Exercicio_PyTorch_Autograd.ipynb","timestamp":1597583489962},{"file_id":"1Je2YaswTBaOSgtJd___RXdEyT0JBveF4","timestamp":1576025052940}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"toc":{"base_numbering":1,"nav_menu":{"height":"117px","width":"252px"},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":"block","toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"cells":[{"cell_type":"markdown","metadata":{"id":"mTVOQpMfhgLM"},"source":["Esté um notebook Colab contendo exercícios de programação em python, numpy e pytorch."]},{"cell_type":"markdown","metadata":{"id":"KMoyGt5gXMgK"},"source":["## Coloque seu nome"]},{"cell_type":"code","metadata":{"id":"iBHbXcibXPRe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629288022243,"user_tz":180,"elapsed":375,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"554f4adb-298b-4014-a654-e41877c8ff7d"},"source":["print('Meu nome é: Guilherme Pereira Albino da Silva, RA: 182786')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Meu nome é: Guilherme Pereira Albino da Silva, RA: 182786\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"e9S5acRbm1Zr"},"source":["# Parte 1:\n","\n","##Exercícios de Processamento de Dados\n","\n","Nesta parte pode-se usar as bibliotecas nativas do python como a `collections`, `re` e `random`. Também pode-se usar o NumPy."]},{"cell_type":"markdown","metadata":{"id":"kxS5h1V8nDn6"},"source":["##Exercício 1.1\n","Crie um dicionário com os `k` itens mais frequentes de uma lista.\n","\n","Por exemplo, dada a lista de itens `L=['a', 'a', 'd', 'b', 'd', 'c', 'e', 'a', 'b', 'e', 'e', 'a']` e `k=2`, o resultado deve ser um dicionário cuja chave é o item e o valor é a sua frequência: {'a': 4, 'e': 3}"]},{"cell_type":"code","metadata":{"id":"QEcxZrxJ7-YR","executionInfo":{"status":"ok","timestamp":1629288027463,"user_tz":180,"elapsed":491,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}}},"source":["import collections\n","import re\n","import random"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"gT08b5Z_nC-j","executionInfo":{"status":"ok","timestamp":1629288029609,"user_tz":180,"elapsed":378,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}}},"source":["def top_k(L, k):\n","    # Escreva aqui o código\n","\n","    # Cria um dicionário com os k itens mais frequentes de uma lista.\n","    # Quando usado \"Counter\" em uma lista, ele conta o número de vez que cada elemento aparece.\n","    # \"most_common\" irá retornar os valores mais comuns encontardos pelo \"Counter\"\n","\n","    return dict(collections.Counter(L).most_common(k))"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KLD_e3C9p4xO"},"source":["Mostre que sua implementação está correta usando uma entrada com poucos itens:"]},{"cell_type":"code","metadata":{"id":"iMW9NiBgnkvA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629288034181,"user_tz":180,"elapsed":378,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"1149d888-0c5d-49a8-afea-9a3153dea56c"},"source":["L = ['f', 'a', 'a', 'd', 'b', 'd', 'c', 'e', 'a', 'b', 'e', 'e', 'a', 'd']\n","k = 3\n","resultado = top_k(L=L, k=k)\n","print(f'resultado: {resultado}')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["resultado: {'a': 4, 'd': 3, 'e': 3}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wBeqZScQqJ0a"},"source":["Mostre que sua implementação é eficiente usando uma entrada com 10M de itens:"]},{"cell_type":"code","metadata":{"id":"O_lhcm4ko8bY","executionInfo":{"status":"ok","timestamp":1629288047863,"user_tz":180,"elapsed":3038,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}}},"source":["import random\n","L = random.choices('abcdefghijklmnopqrstuvwxyz', k=10_000_000)\n","k = 10000"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"L9U-Bgs2o-f_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629288052992,"user_tz":180,"elapsed":3558,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"27e724e9-eba7-47d4-e449-869c45e4f1f8"},"source":["%%timeit\n","resultado = top_k(L=L, k=k)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["1 loop, best of 5: 486 ms per loop\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oJHDaOz_tK38"},"source":["## Exercício 1.2\n","\n","Em processamento de linguagem natural, é comum convertemos as palavras de um texto para uma lista de identificadores dessas palavras. Dado o dicionário `V` abaixo onde as chaves são palavras e os valores são seus respectivos identificadores, converta o texto `D` para uma lista de identificadores.\n","\n","Palavras que não existem no dicionário deverão ser convertidas para o identificador do token `unknown`.\n","\n","O código deve ser insensível a maiúsculas (case-insensitive).\n","\n","Se atente que pontuações (vírgulas, ponto final, etc) também são consideradas palavras."]},{"cell_type":"code","metadata":{"id":"rVzv89trtTPc","executionInfo":{"status":"ok","timestamp":1629288064100,"user_tz":180,"elapsed":383,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}}},"source":["def tokens_to_ids(text, vocabulary):\n","    # escreva o código aqui.\n","    # Converte as letras maiúsculas em minúsculas \n","    text = text.lower()\n","    # Cria uma lista com todas as ocorrências do padrão\n","    text_list = re.findall(r\"[\\w']+|[!#$%&()*+,-./:;<=>?@[\\]^_{|}~]\", text)\n","\n","    # A partir da lista obtida, realização a identificação\n","    token_list = []\n","    for i in text_list:\n","      if i not in vocabulary:\n","        token_list.append(vocabulary['unknown'])\n","      else:\n","        token_list.append(vocabulary[i])\n","\n","    return token_list"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aCGZeiqkY-sm"},"source":["Mostre que sua implementação esta correta com um exemplo pequeno:\n","\n","---\n","\n"]},{"cell_type":"code","metadata":{"id":"iApR1h7gY98E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629288067084,"user_tz":180,"elapsed":373,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"46f427b6-d4f2-4462-c978-b922063ba3ba"},"source":["V = {'eu': 1, 'de': 2, 'gosto': 3, 'comer': 4, '.': 5, 'unknown': -1}\n","D = 'Eu gosto de comer pizza.'\n","\n","print(tokens_to_ids(D, V))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[1, 3, 2, 4, -1, 5]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dWtTMxlXZN25"},"source":["Mostre que sua implementação é eficiente com um exemplo grande:"]},{"cell_type":"code","metadata":{"id":"pxT_g-ZxZUsX","executionInfo":{"status":"ok","timestamp":1629288069823,"user_tz":180,"elapsed":383,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}}},"source":["V = {'eu': 1, 'de': 2, 'gosto': 3, 'comer': 4, '.': 5, 'unknown': -1}\n","D = ' '.join(1_000_000 * ['Eu gosto de comer pizza.'])"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"kp1nataGZU-V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629288087715,"user_tz":180,"elapsed":15517,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"d7044a6b-4613-4e7f-cc5a-fd884f779f36"},"source":["%%timeit\n","resultado = tokens_to_ids(D, V)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["1 loop, best of 5: 2.49 s per loop\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XRfaKfXwRXn_"},"source":["## Exercício 1.3\n","\n","Em aprendizado profundo é comum termos que lidar com arquivos muito grandes.\n","\n","Dado um arquivo de texto onde cada item é separado por `\\n`, escreva um programa que amostre `k` itens desse arquivo aleatoriamente.\n","\n","Nota 1: Assuma amostragem de uma distribuição uniforme, ou seja, todos os itens tem a mesma probablidade de amostragem.\n","\n","Nota 2: Assuma que o arquivo não cabe em memória.\n","\n","Nota 3: Utilize apenas bibliotecas nativas do python."]},{"cell_type":"code","metadata":{"id":"2PsadE9SRG_9","executionInfo":{"status":"ok","timestamp":1629288092881,"user_tz":180,"elapsed":430,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}}},"source":["import random\n","def sample(path: str, k: int):\n","  # Verifica o número de linhas no arquivo\n","  with open(filename, \"r\") as file:\n","      n = -1\n","      for line in file:\n","          n += 1;\n","\n","  # Gera k números aleatórios entr 0 e n\n","  randomList = []\n","\n","  for i in range(0, k):\n","      num = random.randint(0,n)\n","      randomList.append(num)\n","\n","  a_file = open(filename)\n","\n","  # Pega a informação de presente em cada linha da lista\n","  # aleatória gerada.\n","  # Ainda que a lista randomList possua número repetidos,\n","  # esse laço pega a informação uma única vez.\n","  # Por exemplo: randomList = [3, 3, 5]\n","  # A saída será: ['line 3', 'line 5']\n","  item = []\n","  ind = []\n","  for position, line in enumerate(a_file):\n","      if position in randomList:\n","          line = line.partition(\"\\n\")[0]\n","          item.append(line)\n","          ind.append(position)\n","\n","  # Cria uma lista com a informação, de acordo com a ordem\n","  # obtida na lista randomList\n","  # Continuando com o exemplo anterior, a saída final será:\n","  # ['line 3', 'line 3', 'line 5']\n","  amostra = []\n","  for i in range(len(randomList)):\n","      amostra.append(item[ind.index(randomList[i])])\n","      \n","  return amostra"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ycEnlFWxSt0i"},"source":["Mostre que sua implementação está correta com um exemplo pequeno:"]},{"cell_type":"code","metadata":{"id":"vyLJ1e2ZSzC9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629288099125,"user_tz":180,"elapsed":357,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"d3f7efe8-4ddb-44e9-bb08-3eca0eb3e967"},"source":["filename = 'small.txt'\n","total_size = 100\n","n_samples = 10\n","\n","with open(filename, 'w') as fout:\n","    fout.write('\\n'.join(f'line {i}' for i in range(total_size)))\n","\n","samples = sample(path=filename, k=n_samples)\n","print(samples)\n","print(len(samples) == n_samples)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["['line 79', 'line 18', 'line 30', 'line 57', 'line 81', 'line 88', 'line 7', 'line 73', 'line 81', 'line 26']\n","True\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2r4FMiMj12Xg"},"source":["Mostre que sua implementação é eficiente com um exemplo grande:"]},{"cell_type":"code","metadata":{"id":"PUwnNMGg18Ty","executionInfo":{"status":"ok","timestamp":1629288103721,"user_tz":180,"elapsed":365,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}}},"source":["filename = 'large.txt'\n","total_size = 1_000_000\n","n_samples = 10000\n","\n","with open(filename, 'w') as fout:\n","    fout.write('\\n'.join(f'line {i}' for i in range(total_size)))"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"iA9sAZmo0UDN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629289153582,"user_tz":180,"elapsed":1046752,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"c577106e-4ca6-4466-f848-039f44d0fd35"},"source":["%%timeit\n","samples = sample(path=filename, k=n_samples)\n","assert len(samples) == n_samples"],"execution_count":14,"outputs":[{"output_type":"stream","text":["1 loop, best of 5: 2min 52s per loop\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"udS0Ns4etoJs"},"source":["# Parte 2:\n","\n","##Exercícios de Numpy\n","\n","Nesta parte deve-se usar apenas a biblioteca NumPy. Aqui não se pode usar o PyTorch."]},{"cell_type":"markdown","metadata":{"id":"RcMz3Vzjt144"},"source":["##Exercício 2.1\n","\n","Quantos operações de ponto flutuante (flops) de soma e de multiplicação tem a multiplicação matricial $AB$, sendo que a matriz $A$ tem tamanho $m \\times n$ e a matriz $B$ tem tamanho $n \\times p$?"]},{"cell_type":"markdown","metadata":{"id":"4gNXj45RJqUm"},"source":["Resposta:\n","- número de somas: $m \\times p \\times (n - 1)$\n","- número de multiplicações: $m \\times p \\times n$"]},{"cell_type":"markdown","metadata":{"id":"2iI7udBFeDlP"},"source":["## Exercício 2.2\n","\n","Em programação matricial, não se faz o loop em cada elemento da matriz,\n","mas sim, utiliza-se operações matriciais.\n","\n","Dada a matriz `A` abaixo, calcule a média dos valores de cada linha sem utilizar laços explícitos.\n","\n","Utilize apenas a biblioteca numpy."]},{"cell_type":"code","metadata":{"id":"cjrXf18N5KrK","executionInfo":{"status":"ok","timestamp":1629289393912,"user_tz":180,"elapsed":365,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}}},"source":["import numpy as np"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"-fqxgNBW27Z0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629289395495,"user_tz":180,"elapsed":434,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"53d7881b-8225-4792-c504-5dfb17fe948a"},"source":["A = np.arange(24).reshape(4, 6)\n","print(A)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["[[ 0  1  2  3  4  5]\n"," [ 6  7  8  9 10 11]\n"," [12 13 14 15 16 17]\n"," [18 19 20 21 22 23]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J1EmKFrT5g7B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629289396563,"user_tz":180,"elapsed":6,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"9a81fe7c-309a-44ce-a9fc-7fa2aa077417"},"source":["# Escreva sua solução aqui.\n","print(np.mean(A, axis=1))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["[ 2.5  8.5 14.5 20.5]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JtgSAAKjUfcO"},"source":["## Exercício 2.3\n","\n","Seja a matriz $C$ que é a normalização da matriz $A$:\n","$$ C(i,j) = \\frac{A(i,j) - A_{min}}{A_{max} - A_{min}} $$\n","\n","Normalizar a matriz `A` do exercício acima de forma que seus valores fiquem entre 0 e 1."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-12-11T00:00:34.072719Z","start_time":"2019-12-11T00:00:34.036017Z"},"id":"_pDhb2-0eDlS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629289400618,"user_tz":180,"elapsed":570,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"b78e3d6d-2a5d-4fc0-97cd-ed40c67e07cc"},"source":["# Escreva sua solução aqui.\n","C = (A - np.min(A)) / (np.max(A) - np.min(A))\n","print(C)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["[[0.         0.04347826 0.08695652 0.13043478 0.17391304 0.2173913 ]\n"," [0.26086957 0.30434783 0.34782609 0.39130435 0.43478261 0.47826087]\n"," [0.52173913 0.56521739 0.60869565 0.65217391 0.69565217 0.73913043]\n"," [0.7826087  0.82608696 0.86956522 0.91304348 0.95652174 1.        ]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GF_P_GARU62m"},"source":["## Exercício 2.4\n","\n","Modificar o exercício anterior de forma que os valores de cada *coluna* da matriz `A` sejam normalizados entre 0 e 1 independentemente dos valores das outras colunas.\n"]},{"cell_type":"code","metadata":{"id":"6NgVzFOYeDla","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629289403352,"user_tz":180,"elapsed":434,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"9ebc2632-2ae6-4477-c781-e5f9bf1b8d12"},"source":["# Escreva sua solução aqui.\n","D = (A - np.min(A,axis=0)) / (np.max(A,axis=0) - np.min(A,axis=0))\n","print(D)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["[[0.         0.         0.         0.         0.         0.        ]\n"," [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.33333333]\n"," [0.66666667 0.66666667 0.66666667 0.66666667 0.66666667 0.66666667]\n"," [1.         1.         1.         1.         1.         1.        ]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cbXIXsDIUmtp"},"source":["## Exercício 2.5\n","\n","Modificar o exercício anterior de forma que os valores de cada *linha* da matriz `A` sejam normalizados entre 0 e 1 independentemente dos valores das outras linhas.\n"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-12-10T17:56:40.413601Z","start_time":"2019-12-10T17:56:40.405056Z"},"id":"i-5Hv8-heDlW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629289405231,"user_tz":180,"elapsed":372,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"ef17b038-8f76-469f-bd70-277ba5421fad"},"source":["# Escreva sua solução aqui.\n","E = (A - np.min(A,axis=1).reshape(4,1)) / (np.max(A,axis=1) - np.min(A,axis=1)).reshape(4,1)\n","print(E)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["[[0.  0.2 0.4 0.6 0.8 1. ]\n"," [0.  0.2 0.4 0.6 0.8 1. ]\n"," [0.  0.2 0.4 0.6 0.8 1. ]\n"," [0.  0.2 0.4 0.6 0.8 1. ]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QKnLAyL7zgpa"},"source":["## Exercício 2.6\n","\n","A [função softmax](https://en.wikipedia.org/wiki/Softmax_function) é bastante usada em apredizado de máquina para converter uma lista de números para uma distribuição de probabilidade, isto é, os números ficarão normalizados entre zero e um e sua soma será igual à um.\n","\n","Implemente a função softmax com suporte para batches, ou seja, o softmax deve ser aplicado a cada linha da matriz. Deve-se usar apenas a biblioteca numpy. Se atente que a exponenciação gera estouro de representação quando os números da entrada são muito grandes. Tente corrigir isto."]},{"cell_type":"code","metadata":{"id":"lA5W9vxNEmOj","executionInfo":{"status":"ok","timestamp":1629289417342,"user_tz":180,"elapsed":520,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}}},"source":["import numpy as np\n","\n","\n","def softmax(x):\n","    '''\n","    Aplica a função de softmax à matriz `A`.\n","\n","    Entrada:\n","      `A` é uma matriz M x N, onde M é o número de exemplos a serem processados\n","      independentemente e N é o tamanho de cada exemplo.\n","    \n","    Saída:\n","      Uma matriz M x N, onde a soma de cada linha é igual a um.\n","    '''\n","    # Escreva sua solução aqui.\n","\n","    # A função softmax seria: f_x = np.exp(x) / np.sum(np.exp(x))\n","    # Mas isso pode resultar em problemas, no caso do valor de x ser\n","    # muito grande, a exponencial tenderá à infinito, para isso\n","    # subtrai-se, de todos os número da linha, o maior valor presente\n","    # constituindo uma forma numericamente estável.\n","\n","    # Obtém-se o valor máximo de cada linha\n","    max = np.max(x,axis=1, keepdims=True)\n","    # Realiza o cálculo da exponencial dos números, subtraindo pelo\n","    # máximo de cada linha \n","    e_x = np.exp(x - max)\n","    # Os denominadores são calculados\n","    sum = np.sum(e_x,axis=1, keepdims=True)\n","    # Divide-se cada número pelo respectivo denominador da linha\n","    f_x = e_x / sum \n","    \n","    return f_x"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gpxlbh4ND54q"},"source":["Mostre que sua implementação está correta usando uma matriz pequena como entrada:"]},{"cell_type":"code","metadata":{"id":"L6EZ5ZD7HFao","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629289420500,"user_tz":180,"elapsed":396,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"69f81dcf-ad84-4588-da4a-4a75ec194abc"},"source":["A = np.array([[0.5, -1, 1000],\n","              [-2,   0, 0.5]])\n","softmax(A)"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.        , 0.        , 1.        ],\n","       [0.04861082, 0.35918811, 0.59220107]])"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"9j2uXmKH8HF4"},"source":["O código a seguir verifica se sua implementação do softmax está correta. \n","- A soma de cada linha de A deve ser 1;\n","- Os valores devem estar entre 0 e 1"]},{"cell_type":"code","metadata":{"id":"r-sN4STk7qyN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629289423969,"user_tz":180,"elapsed":530,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"7b863719-1e2f-4d62-94c4-30cbb69fbe9b"},"source":["np.allclose(softmax(A).sum(axis=1), 1) and softmax(A).min() >= 0 and softmax(A).max() <= 1"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"B5_ZRWRfCZtI"},"source":["Mostre que sua implementação é eficiente usando uma matriz grande como entrada:"]},{"cell_type":"code","metadata":{"id":"bhUeyrGaJ3J2","executionInfo":{"status":"ok","timestamp":1629289425950,"user_tz":180,"elapsed":477,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}}},"source":["A = np.random.uniform(low=-10, high=10, size=(128, 100_000))"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"jaa-C8XkKJin","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629289429820,"user_tz":180,"elapsed":2438,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"37bbb1f3-08b8-4404-8910-248bc8420695"},"source":["%%timeit\n","softmax(A)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["1 loop, best of 5: 309 ms per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4XE6LaWi81zZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629289432426,"user_tz":180,"elapsed":956,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"a77acf80-f4a9-4c74-fca6-dec734079edb"},"source":["SM = softmax(A)\n","np.allclose(SM.sum(axis=1), 1) and SM.min() >= 0 and SM.max() <= 1"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"Flr1lI5o-HpG"},"source":["## Exercício 2.7\n","\n","A codificação one-hot é usada para codificar entradas categóricas. É uma codificação onde apenas um bit é 1 e os demais são zero, conforme a tabela a seguir.\n","\n","| Decimal | Binary | One-hot\n","| ------- | ------ | -------\n","| 0 | 000    | 1 0 0 0 0 0 0 0\n","| 1 | 001    | 0 1 0 0 0 0 0 0\n","| 2 | 010    | 0 0 1 0 0 0 0 0\n","| 3 | 011    | 0 0 0 1 0 0 0 0\n","| 4 | 100    | 0 0 0 0 1 0 0 0\n","| 5 | 101    | 0 0 0 0 0 1 0 0\n","| 6 | 110    | 0 0 0 0 0 0 1 0\n","| 7 | 111    | 0 0 0 0 0 0 0 1"]},{"cell_type":"markdown","metadata":{"id":"1CqXP_5ABbfo"},"source":["Implemente a função one_hot(y, n_classes) que codifique o vetor de inteiros y que possuem valores entre 0 e n_classes-1.\n"]},{"cell_type":"code","metadata":{"id":"la-02w7qCH7L","executionInfo":{"status":"ok","timestamp":1629289436608,"user_tz":180,"elapsed":363,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}}},"source":["def one_hot(y, n_classes):\n","  # Escreva seu código aqui.\n","  # A função \"np.eye(x)\" retorna \"x\" listas com \"1\" apenas nas diagonais\n","\n","  return np.eye(n_classes)[y]"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"zf5zyZO5Aiz_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629289439304,"user_tz":180,"elapsed":797,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"3a2a0a44-bbb5-4ff4-e770-bd8d003de37d"},"source":["N_CLASSES = 9\n","N_SAMPLES = 10\n","y = (np.random.rand((N_SAMPLES)) * N_CLASSES).astype(np.int)\n","print(y)\n","print(one_hot(y, N_CLASSES))"],"execution_count":29,"outputs":[{"output_type":"stream","text":["[8 1 2 0 8 0 7 5 6 1]\n","[[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6nwuKnQUCzve"},"source":["Mostre que sua implementação é eficiente usando uma matriz grande como entrada:"]},{"cell_type":"code","metadata":{"id":"uwuFy5rWC2tA","executionInfo":{"status":"ok","timestamp":1629289443049,"user_tz":180,"elapsed":357,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}}},"source":["N_SAMPLES = 100_000\n","N_CLASSES = 1_000\n","y = (np.random.rand((N_SAMPLES)) * N_CLASSES).astype(np.int)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"7azMtF7wDJ2_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629289446456,"user_tz":180,"elapsed":1341,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"401e27c9-eacb-4f8e-bbdf-9594d8f53ba8"},"source":["%%timeit\n","one_hot(y, N_CLASSES)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["1 loop, best of 5: 162 ms per loop\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lqMroZay2ubi"},"source":["## Exercício 2.8\n","\n","Implemente uma classe que normalize um array de pontos flutuantes `array_a` para a mesma média e desvio padrão de um outro array `array_b`, conforme exemplo abaixo:\n","```\n","array_a = np.array([-1, 1.5, 0])\n","array_b = np.array([1.4, 0.8, 0.3, 2.5])\n","normalize = Normalizer(array_b)\n","normalized_array = normalize(array_a)\n","print(normalized_array)  # Deve imprimir [0.3187798  2.31425165 1.11696854]\n","```"]},{"cell_type":"code","metadata":{"id":"qaedJ5Cf5Oy2","executionInfo":{"status":"ok","timestamp":1629286946819,"user_tz":180,"elapsed":384,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}}},"source":["# Escreva seu código aqui.\n","# Escreva seu código aqui.\n","def meanStd(data):\n","    \n","    # Calcula a média\n","    mean = sum(data) / len(data)\n","    # Calcula o desvio padrão\n","    std_dev = np.std(data)\n","    \n","    return mean, std_dev\n","\n","\n","\n","def Normalizer(array_a, array_b):\n","    \n","    # Calcula a média e desvio padrão dos dois arrays\n","    mean_a, std_dev_a = meanStd(array_a)\n","    mean_b, std_dev_b = meanStd(array_b)\n","    \n","    # Modifica o devio padrão para o mesmo da referência\n","    x = np.array(array_a) * (std_dev_b/std_dev_a)\n","    # Obtem a média do array com devio padrão novo\n","    mean_x, std_dev_x = meanStd(x)\n","    # Altera-se a média para a mesma da referência\n","    y = x + mean_b - mean_x\n","\n","    return y"],"execution_count":43,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dlkNNU6h5RbR"},"source":["Mostre que seu código está correto com o exemplo abaixo:"]},{"cell_type":"code","metadata":{"id":"Gad6zsbh5a0D","colab":{"base_uri":"https://localhost:8080/","height":231},"executionInfo":{"status":"error","timestamp":1629286950258,"user_tz":180,"elapsed":614,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"1fbd2d09-bbd6-4f2c-b469-59999c967333"},"source":["array_a = [-1, 1.5, 0]\n","array_b = [1.4, 0.8, 0.3, 2.5]\n","normalize = Normalizer(array_b)\n","normalized_array = normalize(array_a)\n","print(normalized_array)"],"execution_count":44,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-a9532092d676>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0marray_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0marray_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnormalize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnormalized_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Normalizer() missing 1 required positional argument: 'array_b'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K5A_l5VbEX03","executionInfo":{"status":"ok","timestamp":1629286956203,"user_tz":180,"elapsed":369,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"1a7d30ef-c769-4c25-8491-e67d103109c4"},"source":["# Eu não conheço a forma acima de se chamar função e variável\n","# com o mesmo nome, com isso, eu alterei um pouco para uma forma\n","# em que estou familiarizado.\n","array_a = [-1, 1.5, 0]\n","array_b = [1.4, 0.8, 0.3, 2.5]\n","normalized_array = Normalizer(array_a, array_b)\n","print(normalized_array)\n","\n","# Imprimer a média e desvio padrão do array referência (array_b)\n","# e do normalized_array\n","print(meanStd(array_b))\n","print(meanStd(normalized_array))"],"execution_count":45,"outputs":[{"output_type":"stream","text":["[0.3187798  2.31425165 1.11696854]\n","(1.25, 0.8200609733428362)\n","(1.2499999999999998, 0.8200609733428361)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vrGVQFUYI_LP"},"source":["# Parte 3:\n","\n","##Exercícios Pytorch: Grafo Computacional e Gradientes\n","\n","Nesta parte pode-se usar quaisquer bibliotecas."]},{"cell_type":"markdown","metadata":{"id":"BIlQdKAuCZtR"},"source":["Um dos principais fundamentos para que o PyTorch seja adequado para deep learning é a sua habilidade de calcular o gradiente automaticamente a partir da expressões definidas. Essa facilidade é implementada através do cálculo automático do gradiente e construção dinâmica do grafo computacional."]},{"cell_type":"markdown","metadata":{"id":"ZF_-dJ2nCZtT"},"source":["## Grafo computacional\n","\n","Seja um exemplo simples de uma função de perda J dada pela Soma dos Erros ao Quadrado (SEQ - Sum of Squared Errors): \n","$$ J = \\sum_i (x_i w - y_i)^2 $$\n","que pode ser reescrita como:\n","$$ \\hat{y_i} = x_i w $$\n","$$ e_i = \\hat{y_i} - y_i $$\n","$$ e2_i = e_i^2 $$\n","$$ J = \\sum_i e2_i $$\n","\n","As redes neurais são treinadas através da minimização de uma função de perda usando o método do gradiente descendente. Para ajustar o parâmetro $w$ precisamos calcular o gradiente $  \\frac{ \\partial J}{\\partial w} $. Usando a\n","regra da cadeia podemos escrever:\n","$$ \\frac{ \\partial J}{\\partial w} = \\frac{ \\partial J}{\\partial e2_i} \\frac{ \\partial e2_i}{\\partial e_i} \\frac{ \\partial e_i}{\\partial \\hat{y_i} } \\frac{ \\partial \\hat{y_i}}{\\partial w}$$ "]},{"cell_type":"markdown","metadata":{"id":"jboejVQMCZtU"},"source":["```\n","    y_pred = x * w\n","    e = y_pred - y\n","    e2 = e**2\n","    J = e2.sum()\n","```"]},{"cell_type":"markdown","metadata":{"id":"n7JmU6qhc2Y2"},"source":["As quatro expressões acima, para o cálculo do J podem ser representadas pelo grafo computacional visualizado a seguir: os círculos são as variáveis (tensores), os quadrados são as operações, os números em preto são os cálculos durante a execução das quatro expressões para calcular o J (forward, predict). O cálculo do gradiente, mostrado em vermelho, é calculado pela regra da cadeia, de trás para frente (backward)."]},{"cell_type":"markdown","metadata":{"id":"KeeEBKl4CZtV"},"source":["<img src=\"https://raw.githubusercontent.com/robertoalotufo/files/master/figures/GrafoComputacional.png\" width=\"600pt\"/>"]},{"cell_type":"markdown","metadata":{"id":"8yZun7wrCZtX"},"source":["Para entender melhor o funcionamento do grafo computacional com os tensores, recomenda-se leitura em:\n","\n","https://pytorch.org/docs/stable/notes/autograd.html"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-12-11T00:23:00.431853Z","start_time":"2019-12-11T00:23:00.414813Z"},"id":"HlT2d-4fCZtZ","executionInfo":{"status":"ok","timestamp":1629289492440,"user_tz":180,"elapsed":4449,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}}},"source":["import torch"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-12-11T00:23:00.863228Z","start_time":"2019-12-11T00:23:00.844457Z"},"id":"xX0QwUduCZtf","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1629289496220,"user_tz":180,"elapsed":366,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"ef2cffc0-97c9-4879-cc0d-8b6e854f13ce"},"source":["torch.__version__"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'1.9.0+cu102'"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"vsqzALS4CZtl"},"source":["**Tensor com atributo .requires_grad=True**\n","\n","Quando um tensor possui o atributo `requires_grad` como verdadeiro, qualquer expressão que utilizar esse tensor irá construir um grafo computacional para permitir posteriormente, após calcular a função a ser derivada, poder usar a regra da cadeia e calcular o gradiente da função em termos dos tensores que possuem o atributo `requires_grad`.\n"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-09-29T03:07:22.117010Z","start_time":"2019-09-29T03:07:22.041861Z"},"id":"foaAb94aCZtm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629289498690,"user_tz":180,"elapsed":361,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"1bb5a856-2e6f-4742-9efa-00fece3a36f8"},"source":["y = torch.arange(0, 8, 2).float()\n","y"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0., 2., 4., 6.])"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-09-29T03:07:28.610934Z","start_time":"2019-09-29T03:07:28.598223Z"},"id":"no6SdSyICZtr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629289500588,"user_tz":180,"elapsed":365,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"42641ea1-f3da-4fa0-a2dc-3299388623b9"},"source":["x = torch.arange(0, 4).float()\n","x"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0., 1., 2., 3.])"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-09-29T03:07:31.523762Z","start_time":"2019-09-29T03:07:31.497683Z"},"id":"eL_i1mwGCZtw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629289502743,"user_tz":180,"elapsed":370,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"b5dea96f-ee4b-4bc2-db13-99647d90b2f4"},"source":["w = torch.ones(1, requires_grad=True)\n","w"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1.], requires_grad=True)"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"qjEl-0l7CZt0"},"source":["## Cálculo automático do gradiente da função perda J"]},{"cell_type":"markdown","metadata":{"id":"8pUh-SCnCZt1"},"source":["Seja a expressão: $$ J = \\sum_i ((x_i  w) - y_i)^2 $$\n","\n","Queremos calcular a derivada de $J$ em relação a $w$."]},{"cell_type":"markdown","metadata":{"id":"eMwwVtJ1CZt2"},"source":["## Forward pass\n","\n","Durante a execução da expressão, o grafo computacional é criado. Compare os valores de cada parcela calculada com os valores em preto da figura ilustrativa do grafo computacional."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-09-29T03:07:36.290122Z","start_time":"2019-09-29T03:07:36.273229Z"},"id":"zp2aK4YhCZt3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629289506587,"user_tz":180,"elapsed":387,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"be349a9f-af66-4c1a-b460-8a7d1eebb58f"},"source":["# predict (forward)\n","y_pred = x * w; print('y_pred =', y_pred)\n","\n","# cálculo da perda J: loss\n","e = y_pred - y; print('e =',e)\n","e2 = e.pow(2) ; print('e2 =', e2)\n","J = e2.sum()  ; print('J =', J)"],"execution_count":37,"outputs":[{"output_type":"stream","text":["y_pred = tensor([0., 1., 2., 3.], grad_fn=<MulBackward0>)\n","e = tensor([ 0., -1., -2., -3.], grad_fn=<SubBackward0>)\n","e2 = tensor([0., 1., 4., 9.], grad_fn=<PowBackward0>)\n","J = tensor(14., grad_fn=<SumBackward0>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XC96wB7PCZt8"},"source":["## Backward pass"]},{"cell_type":"markdown","metadata":{"ExecuteTime":{"end_time":"2017-10-04T15:55:45.308858","start_time":"2017-10-04T15:55:45.304654"},"id":"kKbf4D0CCZt-"},"source":["O `backward()` varre o grafo computacional a partir da variável a ele associada (raiz) e calcula o gradiente para todos os tensores que possuem o atributo `requires_grad` como verdadeiro.\n","Observe que os tensores que tiverem o atributo `requires_grad` serão sempre folhas no grafo computacional.\n","O `backward()` destroi o grafo após sua execução. Esse comportamento é padrão no PyTorch. \n","\n","A título ilustrativo, se quisermos depurar os gradientes dos nós que não são folhas no grafo computacional, precisamos primeiro invocar `retain_grad()` em cada um desses nós, como a seguir. Entretanto nos exemplos reais não há necessidade de verificar o gradiente desses nós."]},{"cell_type":"code","metadata":{"id":"f-CjLPu6clVo","executionInfo":{"status":"ok","timestamp":1629289509937,"user_tz":180,"elapsed":388,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}}},"source":["e2.retain_grad()\n","e.retain_grad()\n","y_pred.retain_grad()"],"execution_count":38,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WtsZS2Bicof-"},"source":["E agora calculamos os gradientes com o `backward()`.\n","\n","w.grad é o gradiente de J em relação a w."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-09-29T03:07:40.267334Z","start_time":"2019-09-29T03:07:40.247422Z"},"id":"Z1lnkb0GCZt_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629289511998,"user_tz":180,"elapsed":618,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"646eeb3c-ebac-49c9-ed7f-62a7e2a2750d"},"source":["if w.grad: w.grad.zero_()\n","J.backward()\n","print(w.grad)"],"execution_count":39,"outputs":[{"output_type":"stream","text":["tensor([-28.])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N1xYDPR_uOcZ"},"source":["Mostramos agora os gradientes que estão grafados em vermelho no grafo computacional:"]},{"cell_type":"code","metadata":{"id":"Enuk2tf0sDyO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629289513957,"user_tz":180,"elapsed":7,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"0df5fdc0-bb68-4d10-a133-29cc9ff97cf8"},"source":["print(e2.grad)\n","print(e.grad)\n","print(y_pred.grad)"],"execution_count":40,"outputs":[{"output_type":"stream","text":["tensor([1., 1., 1., 1.])\n","tensor([ 0., -2., -4., -6.])\n","tensor([ 0., -2., -4., -6.])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LsOThnt8fDJV"},"source":["##Exercício 3.1\n","Calcule o mesmo gradiente ilustrado no exemplo anterior usando a regra das diferenças finitas, de acordo com a equação a seguir, utilizando um valor de $\\Delta w$ bem pequeno.\n","\n","$$ \\frac{\\partial J}{\\partial w} = \\frac{J(w + \\Delta w) - J(w - \\Delta w)}{2 \\Delta w} $$"]},{"cell_type":"code","metadata":{"hidden":true,"id":"62nZAfUoCZu5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629289519219,"user_tz":180,"elapsed":373,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"50bb0f07-4655-40b8-a701-e5d2e16c7816"},"source":["def J_func(w, x, y):\n","    # predict (forward)\n","    y_pred = x * w \n","    # cálculo da perda J: loss\n","    e = y_pred - y\n","    e2 = e.pow(2)\n","    J = e2.sum()\n","\n","    return J\n","\n","# Calcule o gradiente usando a regra diferenças finitas\n","def dJ_diff (w, x, y, grad):\n","\n","  return (J_func((w+grad), x, y) - J_func((w - grad), x, y)) / (2 * grad)\n","\n","# Confira com o valor já calculado anteriormente\n","\n","x = torch.arange(0, 4).float()\n","y = torch.arange(0, 8, 2).float()\n","w = torch.ones(1)\n","grad = 0.001\n","\n","grad = dJ_diff(w, x, y, grad)\n","print('grad=', grad)"],"execution_count":41,"outputs":[{"output_type":"stream","text":["grad= tensor(-28.0008)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"O_Sx1QXZxJ3u"},"source":["##Exercício 3.2\n","\n","Minimizando $J$ pelo gradiente descendente\n","\n","$$ w_{k+1} = w_k - \\lambda \\frac {\\partial J}{\\partial w} $$\n","\n","Supondo que valor inicial ($k=0$) $w_0 = 1$, use learning rate $\\lambda = 0.01$ para calcular o valor do novo $w_{20}$, ou seja, fazendo 20 atualizações de gradientes. Deve-se usar a função `J_func` criada no exercício anterior.\n","\n","Confira se o valor do primeiro gradiente está de acordo com os valores já calculado acima"]},{"cell_type":"code","metadata":{"id":"PNszCOED1Wtu","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1629289527863,"user_tz":180,"elapsed":1069,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"c6d1e870-48e3-4208-d2df-da5be7e01956"},"source":["learning_rate = 0.01\n","iteracoes = 20\n","loss = []\n","\n","x = torch.arange(0, 4).float()\n","y = torch.arange(0, 8, 2).float()\n","w = torch.ones(1)\n","\n","for i in range(iteracoes):\n","    print('i =', i)\n","    J = J_func(w, x, y)\n","    print('J=', J)\n","    grad = dJ_diff(w, x, y, grad)\n","    print('grad =',grad)\n","    w = w - learning_rate * grad\n","    print('w =', w)\n","\n","    loss.append(J)\n","\n","# Plote o gráfico da loss J pela iteração i\n","\n","import matplotlib.pyplot as plt\n","\n","plt.plot(loss)\n","plt.title(\"Loss X Iterações\")\n","plt.xticks(range(iteracoes))\n","plt.xlabel('Iterações')\n","plt.ylabel('Loss')\n","plt.show()"],"execution_count":42,"outputs":[{"output_type":"stream","text":["i = 0\n","J= tensor(14.)\n","grad = tensor(-28.0000)\n","w = tensor([1.2800])\n","i = 1\n","J= tensor(7.2576)\n","grad = tensor(-20.1600)\n","w = tensor([1.4816])\n","i = 2\n","J= tensor(3.7623)\n","grad = tensor(-14.5152)\n","w = tensor([1.6268])\n","i = 3\n","J= tensor(1.9504)\n","grad = tensor(-10.4510)\n","w = tensor([1.7313])\n","i = 4\n","J= tensor(1.0111)\n","grad = tensor(-7.5247)\n","w = tensor([1.8065])\n","i = 5\n","J= tensor(0.5241)\n","grad = tensor(-5.4178)\n","w = tensor([1.8607])\n","i = 6\n","J= tensor(0.2717)\n","grad = tensor(-3.9008)\n","w = tensor([1.8997])\n","i = 7\n","J= tensor(0.1409)\n","grad = tensor(-2.8086)\n","w = tensor([1.9278])\n","i = 8\n","J= tensor(0.0730)\n","grad = tensor(-2.0222)\n","w = tensor([1.9480])\n","i = 9\n","J= tensor(0.0379)\n","grad = tensor(-1.4560)\n","w = tensor([1.9626])\n","i = 10\n","J= tensor(0.0196)\n","grad = tensor(-1.0483)\n","w = tensor([1.9730])\n","i = 11\n","J= tensor(0.0102)\n","grad = tensor(-0.7548)\n","w = tensor([1.9806])\n","i = 12\n","J= tensor(0.0053)\n","grad = tensor(-0.5434)\n","w = tensor([1.9860])\n","i = 13\n","J= tensor(0.0027)\n","grad = tensor(-0.3913)\n","w = tensor([1.9899])\n","i = 14\n","J= tensor(0.0014)\n","grad = tensor(-0.2817)\n","w = tensor([1.9928])\n","i = 15\n","J= tensor(0.0007)\n","grad = tensor(-0.2028)\n","w = tensor([1.9948])\n","i = 16\n","J= tensor(0.0004)\n","grad = tensor(-0.1460)\n","w = tensor([1.9962])\n","i = 17\n","J= tensor(0.0002)\n","grad = tensor(-0.1051)\n","w = tensor([1.9973])\n","i = 18\n","J= tensor(0.0001)\n","grad = tensor(-0.0757)\n","w = tensor([1.9981])\n","i = 19\n","J= tensor(5.3059e-05)\n","grad = tensor(-0.0545)\n","w = tensor([1.9986])\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"JBXxBmWGK3IU"},"source":["##Exercício 3.3\n","\n","Repita o exercício 2 mas usando agora o calculando o gradiente usando o método backward() do pytorch. Confira se o primeiro valor do gradiente está de acordo com os valores anteriores. Execute essa próxima célula duas vezes. Os valores devem ser iguais.\n"]},{"cell_type":"code","metadata":{"id":"lMP4d5vtHtqy","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1629289534949,"user_tz":180,"elapsed":1253,"user":{"displayName":"Guilherme Pereira Albino da Silva","photoUrl":"","userId":"07971392613373651702"}},"outputId":"5a27891a-dd5e-498a-ba79-be9eac236764"},"source":["learning_rate = 0.01\n","iteracoes = 20\n","\n","x = torch.arange(0, 4).float()\n","y = torch.arange(0, 8, 2).float()\n","w = torch.ones(1, requires_grad=True)\n","\n","for i in range(iteracoes):\n","    print('i =', i)\n","    J = J_func(w, x, y)\n","    print('J=', J)\n","    J.backward()\n","    grad = w.grad\n","    print('grad =',grad)\n","    w = w - learning_rate * grad\n","    w.retain_grad()\n","    print('w =', w)\n","\n","# Plote aqui a loss pela iteração\n","\n","import matplotlib.pyplot as plt\n","\n","plt.plot(loss)\n","plt.title(\"Loss X Iterações\")\n","plt.xticks(range(iteracoes))\n","plt.xlabel('Iterações')\n","plt.ylabel('Loss')\n","plt.show()"],"execution_count":43,"outputs":[{"output_type":"stream","text":["i = 0\n","J= tensor(14., grad_fn=<SumBackward0>)\n","grad = tensor([-28.])\n","w = tensor([1.2800], grad_fn=<SubBackward0>)\n","i = 1\n","J= tensor(7.2576, grad_fn=<SumBackward0>)\n","grad = tensor([-20.1600])\n","w = tensor([1.4816], grad_fn=<SubBackward0>)\n","i = 2\n","J= tensor(3.7623, grad_fn=<SumBackward0>)\n","grad = tensor([-14.5152])\n","w = tensor([1.6268], grad_fn=<SubBackward0>)\n","i = 3\n","J= tensor(1.9504, grad_fn=<SumBackward0>)\n","grad = tensor([-10.4509])\n","w = tensor([1.7313], grad_fn=<SubBackward0>)\n","i = 4\n","J= tensor(1.0111, grad_fn=<SumBackward0>)\n","grad = tensor([-7.5247])\n","w = tensor([1.8065], grad_fn=<SubBackward0>)\n","i = 5\n","J= tensor(0.5241, grad_fn=<SumBackward0>)\n","grad = tensor([-5.4178])\n","w = tensor([1.8607], grad_fn=<SubBackward0>)\n","i = 6\n","J= tensor(0.2717, grad_fn=<SumBackward0>)\n","grad = tensor([-3.9008])\n","w = tensor([1.8997], grad_fn=<SubBackward0>)\n","i = 7\n","J= tensor(0.1409, grad_fn=<SumBackward0>)\n","grad = tensor([-2.8086])\n","w = tensor([1.9278], grad_fn=<SubBackward0>)\n","i = 8\n","J= tensor(0.0730, grad_fn=<SumBackward0>)\n","grad = tensor([-2.0222])\n","w = tensor([1.9480], grad_fn=<SubBackward0>)\n","i = 9\n","J= tensor(0.0379, grad_fn=<SumBackward0>)\n","grad = tensor([-1.4560])\n","w = tensor([1.9626], grad_fn=<SubBackward0>)\n","i = 10\n","J= tensor(0.0196, grad_fn=<SumBackward0>)\n","grad = tensor([-1.0483])\n","w = tensor([1.9730], grad_fn=<SubBackward0>)\n","i = 11\n","J= tensor(0.0102, grad_fn=<SumBackward0>)\n","grad = tensor([-0.7548])\n","w = tensor([1.9806], grad_fn=<SubBackward0>)\n","i = 12\n","J= tensor(0.0053, grad_fn=<SumBackward0>)\n","grad = tensor([-0.5434])\n","w = tensor([1.9860], grad_fn=<SubBackward0>)\n","i = 13\n","J= tensor(0.0027, grad_fn=<SumBackward0>)\n","grad = tensor([-0.3913])\n","w = tensor([1.9899], grad_fn=<SubBackward0>)\n","i = 14\n","J= tensor(0.0014, grad_fn=<SumBackward0>)\n","grad = tensor([-0.2817])\n","w = tensor([1.9928], grad_fn=<SubBackward0>)\n","i = 15\n","J= tensor(0.0007, grad_fn=<SumBackward0>)\n","grad = tensor([-0.2028])\n","w = tensor([1.9948], grad_fn=<SubBackward0>)\n","i = 16\n","J= tensor(0.0004, grad_fn=<SumBackward0>)\n","grad = tensor([-0.1460])\n","w = tensor([1.9962], grad_fn=<SubBackward0>)\n","i = 17\n","J= tensor(0.0002, grad_fn=<SumBackward0>)\n","grad = tensor([-0.1052])\n","w = tensor([1.9973], grad_fn=<SubBackward0>)\n","i = 18\n","J= tensor(0.0001, grad_fn=<SumBackward0>)\n","grad = tensor([-0.0757])\n","w = tensor([1.9981], grad_fn=<SubBackward0>)\n","i = 19\n","J= tensor(5.3059e-05, grad_fn=<SumBackward0>)\n","grad = tensor([-0.0545])\n","w = tensor([1.9986], grad_fn=<SubBackward0>)\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"GulfYtzBMx2e"},"source":["##Exercício 3.4\n","\n","Quais são as restrições na escolha dos valores de $\\Delta w$ no cálculo do gradiente por diferenças finitas?"]},{"cell_type":"markdown","metadata":{"id":"TXQGEyvtiTAR"},"source":["**Resposta:**\n","\n","1) A primeira restrição para escolha dos valores de $\\Delta w$, encontra-se no fato de que deve ser diferente de 0, uma vez que está no denominador da função $\\frac{\\partial J}{\\partial w} $. Além disso, caso $\\Delta w$ fosse zero o numerador seria: $J(w) - J(w)$\n","\n","2) $\\Delta w$ deve ser pequeno e positivo, desse modo aumenta-se a precisão do modelo, contudo quanto menor for, maior será o custo computacional e mais iterações serão necessárias até alcançar a estabilidade."]},{"cell_type":"markdown","metadata":{"id":"WsrSF8GEiXk4"},"source":["##Exercício 3.5\n","\n","Até agora trabalhamos com $w$ contendo apenas um parâmetro. Suponha agora que $w$ seja uma matriz com $N$ parâmetros e que o custo para executar $(x_i w - y_i)^2$ seja $O(N)$.\n","> a) Qual é o custo computacional para fazer uma única atualização (um passo de gradiente) dos parâmetros de $w$ usando o método das diferencas finitas?\n",">\n","> b) Qual é o custo computacional para fazer uma única atualização (um passo de gradiente) dos parâmetros de $w$ usando o método do backpropagation?\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_4Pna3bcicHj"},"source":["**Resposta (justifique):**\n","\n","**a)** No método das diferenças finitas, faz-se necessário calcular duas vez a derivada parcial de $J$, em função da variável $w$. Com isso, o custo computacional para uma única atualização é $2*O(N)$\n","\n","**b)** Ao contrário do método das diferenças finitas, o método do backpropagation só precisa calcular $\\frac{\\partial J}{\\partial w} $ uma única vez, com isso, o custo computacional para uma única atualização é $O(N)$"]},{"cell_type":"markdown","metadata":{"id":"35I5w8EZdjIo"},"source":["##Exercício 3.6\n","\n","Qual o custo (entropia cruzada) esperado para um exemplo (uma amostra) no começo do treinamento de um classificador inicializado aleatoriamente?\n","\n","A equação da entropia cruzada é:\n","$$L = - \\sum_{j=0}^{K-1} y_j \\log p_j, $$\n","Onde:\n","\n","- K é o número de classes;\n","\n","- $y_j=1$ se $j$ é a classe do exemplo (ground-truth), 0 caso contrário. Ou seja, $y$ é um vetor one-hot;\n","\n","- $p_j$ é a probabilidade predita pelo modelo para a classe $j$.\n","\n","A resposta tem que ser em função de uma ou mais das seguintes variáveis:\n","\n","- K = número de classes\n","\n","- B = batch size\n","\n","- D = dimensão de qualquer vetor do modelo\n","\n","- LR = learning rate"]},{"cell_type":"markdown","metadata":{"id":"swTOphiVs6eN"},"source":["**Resposta:** O custo (entropia cruzada) esperado para um exemplo (uma amostra) no começo do  treinamento de um classificador inicializado aleatoriamente pode ser dada pela equação: $$O(K * D * B)$$\n","\n","\n","O custo do algoritmo depende da dimensão do vetor do modelo (D), do batch size (B) e do número de classes (K)."]},{"cell_type":"markdown","metadata":{"id":"3UNdHqgSB6S9"},"source":["Fim do notebook."]}]}